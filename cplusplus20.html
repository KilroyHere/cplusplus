<!DOCTYPE html><html><head>
<meta charset="UTF-8">
<title> C++ Annotations Version 11.5.0 </title>
<link rel="stylesheet" type="text/css" href="cplusplus.css"><style type="text/css">
    figure {text-align: center;}
    img {vertical-align: center;}
    .XXfc {margin-left:auto;margin-right:auto;}
    .XXtc {text-align: center;}
    .XXtl {text-align: left;}
    .XXtr {text-align: right;}
    .XXvt {vertical-align: top;}
    .XXvb {vertical-align: bottom;}
</style>
<link rel="stylesheet" type="text/css" href="cplusplus.css"></head>
<body >
<hr>
<ul>
    <li> <a href="cplusplus.html">Table of Contents</a>
    <li> <a href="cplusplus19.html">Previous Chapter</a>
    <li> <a href="cplusplus21.html">Next Chapter</a>
</ul>
<hr>
<a name="THREADING"></a><a name="l492"></a>
<h1 >Chapter 20: Multi Threading</h1>
The 98 <strong >C++</strong> standard did not acknowledge the existence of
multi-threading. Between then and the release of the current <strong >C++</strong> standard
computers have evolved to multi-core machines, and using multi-threading by
now is a real option to consider when developing software.
<p>
<a name="PTHREADS"></a>
Multi-threading is an extensive and complex subject, and many
good reference texts on the subject exist. The <strong >C++</strong> multi-threading is
built upon the facilities offered by the <a name="an2522"></a><em >pthreads</em> library (cf. 
    <a name="an2523"></a>Nichols, B, <em >et al.</em>'s
        <a href="http://oreilly.com/catalog/">Pthreads Programming</a>, O'Reilly
        <a name="an2524"></a><a name="an2525"></a>). However,
in line with <strong >C++</strong>'s current-day philosophy the multi-threading
implementation offered by the language offers a high level interface to
multi-threading, and using the raw pthread building blocks is hardly ever
necessary (cf. <a name="an2526"></a>Williams, A. (2012): <strong >C++ Concurrency in action</strong>).  
<p>
This chapter covers the facilities for multi-threading as supported by
<strong >C++</strong>. Although the coverage aims at providing the tools and examples
allowing you to create your own multi-threaded programs, coverage necessarily
is far from complete. The topic of multi threading is too extensive for
that. The mentioned reference texts provide a good starting point for any
further study of multi threading.
<p>
A <a name="an2527"></a><em >thread of execution</em> (commonly abbreviated to a <a name="an2528"></a><em >thread</em>) is a single
flow of control within a program. It differs from a separately executed
program, as created by the <a name="an2529"></a><strong >fork</strong>(1) system call in the sense that threads
all run inside one program, while <strong >fork</strong>(1) creates independent copies of a
running program. Multi-threading means that multiple tasks are being executed
in parallel inside one program, and no assumptions can be made as to which
thread is running first or last, or at what moment in time. Especially when
the number of threads does not exceed the number of cores, each thread may be
active at the same time. If the number of threads exceed the number of cores,
the operating system will resort to <a name="an2530"></a><em >task switching</em>, offering each thread
time slices in which it can perform its tasks. Task switching takes time, and
the law of diminishing returns applies here as well: if the number of threads
greatly exceeds the number of available cores (also called
<a name="an2531"></a><em >overpopulation</em>), then the overhead incurred may exceed the benefit of
being able to run multiple tasks in parallel.
<p>
Since all threads are running inside one single program, all threads share the
program's data and code. When the same data are accessed by multiple threads,
and at least one of the threads is modifying these data, access must be
synchronized to avoid that threads read data while these data are being
modified by other threads, and to avoid that multiple threads modify the same
data at the same time.
<p>
So how do we run a multi-threaded program in <strong >C++</strong>? Let's look at <em >hello
world</em>, the multi-threaded way:
        <pre>
     1: #include &lt;iostream&gt;
     2: #include &lt;thread&gt;
     3: 
     4: void hello()
     5: {
     6:     std::cout &lt;&lt; "hello world!\n";
     7: }
     8: 
     9: int main()
    10: {
    11:     std::thread hi(hello);
    12:     hi.join();
    13: }
</pre>
    <ul>
    <li> At line 2 the header <code >thread</code> is included, informing the compiler
about the existence of the class <code >std::thread</code> (cf. section <a href="cplusplus20.html#THREAD">20.1.2</a>);
<p>
<li> At line 11 the <code >std::thread hi</code> object is created. It is provided
with the name of a function (hello) which will be called in a separate
thread. Actually, the second thread, running <code >hello</code>, is immediately started
when a <code >std::thread</code> is defined this way;
<p>
<li> The <code >main</code> function itself also represents a thread: the program's
first thread. It should wait until the second thread has finished. This
is realized in line 12, where <code >hi.join()</code> waits until the thread <code >hi</code>
has finished its job. Since there are no further statements in <code >main</code>, the
program itself ends immediately thereafter.
<p>
<li> The function <code >hello</code> itself, defined in lines 4 through 7, is
trivial: it simply inserts the text `<code >hello world</code>' into <code >cout</code>, and 
terminates, thus ending the second thread.
    </ul>
<p>
When compiling multi-threaded programs using the GNU <code >g++</code> compiler the 
    <a name="an2532"></a><code >-pthread</code>
        <a name="an2533"></a><a name="an2534"></a>
 option must be specified. 
<p>
To create a multi-threaded program defined in a source file <code >multi.cc</code>
the <code >g++</code> compiler can be called like this:
        <pre>
    g++ --std=c++14 -pthread -Wall multi.cc
</pre>
<p>
<a name="THREADS"></a><a name="l493"></a>
<h2 >20.1: Multi Threading</h2>
In <strong >C++</strong> multi threading may be implemented at various levels of abstraction. In
general the highest level of abstraction which is available to implement a
mult-threaded problem should be used. Not so much because it's often simpler
than using lower levels of abstraction, but because higher levels of
abstraction are usually semantically closer to the original problem
description, resulting in code which is easier to understand and therefore
easier to maintain.  Also, high-abstraction classes also provide exception
safety and prevent the occurrence of memory leaks.
<p>
<strong >C++</strong>'s main tool for creating multi-threaded programs is the class
<code >std::thread</code>, and some examples of its use have already been shown at the
beginning of this chapter. 
<p>
Characteristics of individual threads can be queried from the
<code >std::this_thread</code> namespace. Also, <code >std::this_thread</code> offers some control
over the behavior of an individual thread.
<p>
To synchronize access to shared data <strong >C++</strong> offers <em >mutexes</em> (implemented
by the class <code >std::mutex</code>) and <em >condition variables</em> (implemented by the
class <code >std::condition_variable</code>).
<p>
Members of these classes may throw <code >system_error</code> objects (cf. section
<a href="cplusplus10.html#SYSTEMERROR">10.9</a>) when encountering a low-level error condition.
<p>
<a name="l494"></a>
<h3 >20.1.1: The namespace std::this_thread</h3>
    The <a name="an2535"></a><a name="an2536"></a> <code >namespace std::this_thread</code>
contains functions that are uniquely associated with the currently running
thread.
<p>
Before using the namespace <code >this_thread</code> the <a name="an2537"></a><code >&lt;thread&gt;</code> header file must
be included.
<p>
Inside the <code >std::this_thread</code> namespace several free functions are defined,
providing information about the current thread or that can be used to control
its behavior:
    <ul>
    <li><a name="an2538"></a><code >thread::id this_thread::get_id() noexcept</code>:<br/>returns an object of type <code >thread::id</code> that identifies the currently
active thread of execution. For an active thread the returned <code >id</code> is unique
in the sense that it maps 1:1 to the currently active thread, and is not
returned by any other thread. If a thread is currently not running
<a name="an2539"></a><code >thread::id()</code> is returned by the <code >std::thread</code> object's <code >get_id</code>
member.
<p>
<li><a name="an2540"></a><code >void yield() noexcept</code>:<br/>when a thread calls <code >this_thread::yield()</code> the current thread is
briefly suspended, allowing other (waiting) threads to start.
<p>
<li><a name="an2541"></a><code >void sleep_for(chrono::duration&lt;Rep, Period&gt; const &amp;relTime)
            noexcept</code>:<br/>when a thread calls <code >this_thread::sleep_for(...)</code> it is suspended
for the amount of time that's specified in its argument. E.g.,
   <pre>
std::this_thread::sleep_for(std::chrono::seconds(5));
</pre>
<p>
<li><a name="an2542"></a><code >void sleep_until(chrono::time_point&lt;Clock, Duration&gt; const &amp;absTime)
            noexcept</code>:<br/>when a thread calls this member it is suspended until the specified
<code >absTime</code> is in the past. The next example has the same effect as the
previous example:
   <pre>
// assume using namespace std
this_thread::sleep_until(chrono::system_clock().now() + chrono::seconds(5));
</pre>
<p>
Conversely, the <code >sleep_until</code> call in the next example immediately
returns:
   <pre>
this_thread::sleep_until(chrono::system_clock().now() - chrono::seconds(5));
</pre>
<p>
</ul>
<p>
<a name="THREAD"></a><a name="l495"></a>
<h3 >20.1.2: The class std::thread</h3>
    Multi threading in <strong >C++</strong> starts off with objects of the class
<a name="an2543"></a><code >std::thread</code>. Each object of this class handles a separate
thread.
<p>
Before using <code >Thread</code> objects the <a name="an2544"></a><code >&lt;thread&gt;</code> header file must be included.
<p>
Thread objects can be constructed in various ways:
    <ul>
    <li><code >thread() noexcept</code>:<br/>The default constructor creates a <code >thread</code> object. As it receives no
function to execute, it does not start a separate thread of execution. It is
used, e.g., as a data member of a class, allowing class objects to start a
separate thread at some later point in time;
<p>
<li><code >thread(thread &amp;&amp;tmp) noexcept</code>:<br/>The move constructor takes ownership of the thread controlled by
<code >tmp</code>, while <code >tmp</code>, if it runs a thread, loses control over its
thread. Following this, <code >tmp</code> is in its default state, and the newly created
thread is responsible for calling, e.g., <code >join</code>.
<p>
<li><code >explicit thread(Fun &amp;&amp;fun, Args &amp;&amp;...args)</code>:<br/>This <em >member template</em> (cf. section <a href="cplusplus22.html#MEMTEMP">22.1.3</a>) expects a function
(or functor) as its first argument. The function is immediately started as a
separate thread. If the function (or functor) expects arguments, then these
arguments can be passed to the <code >thread's</code> constructor immediately following
its first (function) argument. Additional arguments are passed with their
proper types and values to <code >fun</code>. Following the <code >thread</code> object's
construction, a separately running thread of execution is started.
<p>
The notation <code >Arg &amp;&amp;...args</code> indicates that any additional arguments are
passed as is to the function. The types of the arguments that are passed to
the <code >thread</code> constructor and that are expected by the called function must
match: values must be values, references must be reference, r-value references
must be r-value references (or move construction must be supported). The
following example illustrates this requirement:
    <pre>
     1: #include &lt;iostream&gt;
     2: #include &lt;thread&gt;
     3: 
     4: using namespace std;
     5: 
     6: struct NoMove
     7: {
     8:     NoMove() = default;
     9:     NoMove(NoMove &amp;&amp;tmp) = delete;
    10: };
    11: 
    12: struct MoveOK
    13: {
    14:     int d_value = 10;
    15: 
    16:     MoveOK() = default;
    17:     MoveOK(MoveOK const &amp;) = default;
    18: 
    19:     MoveOK(MoveOK &amp;&amp;tmp)
    20:     {
    21:         d_value = 0;
    22:         cout &lt;&lt; "MoveOK move cons.\n";
    23:     }
    24: };
    25: 
    26: void valueArg(int value)
    27: {}
    28: void refArg(int &amp;ref)
    29: {}
    30: void r_refArg(int &amp;&amp;tmp)
    31: {
    32:     tmp = 100;
    33: }
    34: void r_refNoMove(NoMove &amp;&amp;tmp)
    35: {}
    36: void r_refMoveOK(MoveOK &amp;&amp;tmp)
    37: {}
    38: 
    39: int main()
    40: {
    41:     int value = 0;
    42: 
    43:     std::thread(valueArg,   value).join();
    44:     std::thread(refArg,     ref(value)).join();
    45:     std::thread(r_refArg,   move(value)).join();
    46: 
    47: //  std::thread(refArg,     value);
    48: 
    49:     std::thread(r_refArg,   value).join();
    50:     cout &lt;&lt; "value after r_refArg: " &lt;&lt; value &lt;&lt; '\n';
    51: 
    52: //  std::thread(r_refNoMove, NoMove());
    53: 
    54:     NoMove noMove;
    55: //  std::thread(r_refNoMove, noMove).join();
    56: 
    57:     MoveOK moveOK;
    58:     std::thread(r_refMoveOK, moveOK).join();
    59:     cout &lt;&lt; moveOK.d_value &lt;&lt; '\n';
    60: }
</pre>
    <ul>
    <li> At lines 43 through 45 we see a value, reference, and and r-value
reference being passed to a <code >std::thread</code>: with 
the functions running the threads expecting matching argument types.
<p>
<li> Line 47 fails to compile, as a value argument doesn't match the
reference expected by <code >refArg</code>. Note that this problem was solved in line 43
by using the <code >std::ref</code> function.
<p>
<li> On the other hand lines 49 and 58 compile OK, as <code >int</code> values and
class-types supporting move operations can be passed as values to functions
expecting r-value references. In this case notice that the functions expecting
the r-value references do not access the provided arguments (except for the
actions performed by their move constructors), but use move construction to
create temporary values or objects on which the functions operate.
<p>
<li> Lines 52 and 55 won't compile as the <code >NoMove</code> struct doesn't offer
a move constructor.
    </ul>
<p>
Be careful when passing local variables as arguments to thread objects: if
the thread continues to run when the function whose local variables are used
terminates, then the thread suddenly uses wild pointers or wild references, as
the local variables no longer exist. To prevent this from happening
(illustrated by the next example) do as follows:
        <ul>
        <li> pass an anonymous copy of the local variable as argument to the
<code >thread</code> constructor, or
<p>
<li> call <code >join</code> on the thread object to ensure that the thread has
finished within the local variable's lifetime.
        </ul>
<p>
<pre>
     1: #include &lt;iostream&gt;
     2: #include &lt;thread&gt;
     3: #include &lt;string&gt;
     4: #include &lt;chrono&gt;
     5: 
     6: void threadFun(std::string const &amp;text)
     7: {
     8:     for (size_t iter = 1; iter != 6; ++iter)
     9:     {
    10:         std::cout &lt;&lt; text &lt;&lt; '\n';
    11:         std::this_thread::sleep_for(std::chrono::seconds(1));
    12:     }
    13: }
    14: 
    15: std::thread safeLocal()
    16: {
    17:     std::string text = "hello world";
    18:     return std::thread(threadFun, std::string{ text });
    19: }
    20: 
    21: int main()
    22: {
    23:     std::thread local(safeLocal());
    24:     std::cout &lt;&lt; "safeLocal has ended\n";
    25:     local.join();
    26: }
</pre>
    In line 18 be sure not to call <code >std::ref(text)</code> instead of
<code >std::string{ text }</code>.
<p>
If the thread cannot be created a <code >std::system_error</code> exception is
thrown.
<p>
Since this constructor not only accepts functions but also function objects as
its first argument, a <a name="an2545"></a><em >local context</em> may be passed to the function
object's constructor. Here is an example of a thread receiving a function
object using a local context:
        <pre>
    #include &lt;iostream&gt;
    #include &lt;thread&gt;
    #include &lt;array&gt;

    using namespace std;

    class Functor
    {
        array&lt;int, 30&gt; &amp;d_data;
        int d_value;

        public:
            Functor(array&lt;int, 30&gt; &amp;data, int value)
            :
                d_data(data),
                d_value(value)
            {}
            void operator()(ostream &amp;out)
            {
                for (auto &amp;value: d_data)
                {
                    value = d_value++;
                    out &lt;&lt; value &lt;&lt; ' ';
                }
                out &lt;&lt; '\n';
            }
    };

    int main()
    {
        array&lt;int, 30&gt; data;
        Functor functor{ data, 5 };
        thread funThread{ functor, ref(cout) };
        funThread.join();
    };
</pre>
<p>
</ul>
    The class <code >std::thread</code> does not provide a copy constructor.
<p>
The following members are available:
    <ul>
    <li><code >thread &amp;operator=(thread &amp;&amp;tmp) noexcept</code>:
       <blockquote >If the operator's left-hand side operand (lhs) is a joinable
thread, then <code >terminate</code> is called. Otherwise, <code >tmp</code> is assigned to the
operator's lhs and <code >tmp's</code> state is changed to the thread's default state
(i.e., <code >thread()</code>).</blockquote>
<p>
<li><a name="an2546"></a><code >void detach()</code>:<br/>Requires <code >joinable</code> (see below) to return <code >true</code>.  The thread for
which <code >detach</code> is called continues to run. The (e.g., parent) thread calling
<code >detach</code> continues immediately beyond the <code >detach</code>-call.  After calling
<code >object.detach()</code>, `<code >object</code>' no longer represents the (possibly still
continuing but now detached) thread of execution. It is the detached thread's
implementation's responsibility to release its resources when its execution
ends.
<p>
Since <code >detach</code> disconnects a thread from the running program, e.g.,
<code >main</code> no longer can wait for the thread's completion.  As a program
ends when <code >main</code> ends, its still running detached threads also stop, and
a program may not properly finish all its threads, as demonstrated by
the following example: 
            <pre>
    #include &lt;thread&gt;
    #include &lt;iostream&gt;
    #include &lt;chrono&gt;

    void fun(size_t count, char const *txt)
    {
        for (; count--; )
        {
            std::this_thread::sleep_for(std::chrono::milliseconds(100));
            std::cout &lt;&lt; count &lt;&lt; ": " &lt;&lt; txt &lt;&lt; std::endl;
        }
    }

    int main()
    {
        std::thread first(fun, 5, "hello world");
        first.detach();

        std::thread second(fun, 5, "a second thread");
        second.detach();

        std::this_thread::sleep_for(std::chrono::milliseconds(400));
        std::cout &lt;&lt; "leaving" &lt;&lt; std::endl;
    }
</pre>
<p>
A detached thread may very well continue to run after the function that
launched it has finished. Here, too, you should be very careful not to pass
local variables to the detached thread, as their references or pointers will
be undefined once the function defining the local variables terminates:
            <pre>
#include &lt;iostream&gt;
#include &lt;thread&gt;
#include &lt;chrono&gt;

using namespace std;
using namespace chrono;

void add(int const &amp;p1, int const &amp;p2)
{
    this_thread::sleep_for(milliseconds(200));
    cerr &lt;&lt; p1 &lt;&lt; " + " &lt;&lt; p2 &lt;&lt; " = " &lt;&lt; (p1 + p2) &lt;&lt; '\n';
}

void run()
{
    int v1 = 10;
    int v2 = 20;

//  thread(add, ref(v1), ref(v2)).detach();     // DON'T DO THIS
    thread(add, int(v1), int(v2)).detach();     // this is OK: own copies
}

void oops()
{
    int v1 = 0;
    int v2 = 0;
}

int main()
{
    run();
    oops();
    this_thread::sleep_for(seconds(1));
}
</pre>
<p>
<li><a name="an2547"></a><code >id get_id() const noexcept</code>:<br/>If the current object does not represent a running thread 
<a name="an2548"></a><code >thread::id()</code> is returned. Otherwise, the thread's unique ID
(also obtainable from with the thread from <code >this_thread::get_id()</code>) is
returned.
<p>
<li><a name="an2549"></a><code >void join()</code>:<br/>Requires <code >joinable</code> to return <code >true</code>.  If the thread for which
<code >join</code> is called hasn't finished yet then the thread calling <code >join</code> will
be suspended (also called <em >blocked</em>) until the thread for which <code >join</code> is
called has completed. Following its completion the object whose <code >join</code>
member was called no longer represents a running thread, and its <code >get_id</code>
member will return <code >std::thread::id()</code>.
<p>
This member was used in several examples shown so far. As noted: when
<code >main</code> ends while a joinable thread is still running, <code >terminate</code> is
called, aborting the program.
<p>
<li><a name="an2550"></a><code >bool joinable() const noexcept</code>:<br/>returns <code >object.get_id() != id()</code>, where <code >object</code> is the
<code >thread</code> object for which <code >joinable</code> was called.
<p>
<li><a name="an2551"></a><code >void swap(thread &amp;other) noexcept</code>:<br/>The states of the <code >thread</code> object for which <code >swap</code> was called and
<code >other</code> are swapped. Note that threads may always be swapped, even when
their thread functions are currently being executed.
<p>
<li><a name="an2552"></a><code >unsigned thread::hardware_concurrency() noexecpt</code>:<br/>This static member returns the number of threads that can run at the
same time on the current computer. On a stand-alone multi-core computer it
(probably) returns the number of cores.
    </ul>
<p>
Things to note:
    <ul>
    <li> When intending to define an anonymous thread it may appear not to
start, unless you immediately also call <code >join</code>. E.g.,
            <pre>
void doSomething();
int main()
{
    thread(doSomething);        // nothing happens??
    thread(doSomething).join()  // doSomething is executed??
}
</pre>
<p>
This similar to the situation we encountered in section <a href="cplusplus07.html#UNIFORMINIT">7.5</a>:
the first statement doesn't define an anonymous <code >thread</code> object at all. It
simply defines the <code >thread</code> object <code >doSomething</code>. Consequently,
compilation of the second statement fails, as there is no <code >thread(thread &amp;)</code>
constructor. When the first statement is omitted, the <code >doSomething</code> function
is executed by the second statement. If the second statement is omitted, a
default constructed <code >thread</code> object by the name of <code >doSomething</code> is
defined.
<p>
<li> A thread only starts after its construction has completed. This
includes move constructions or move assignments. E.g., in a statement like
        <pre>
    thread object(thread(doSomething));
</pre>
<p>
the move constructor is used to transfer control from an anonymous thread
executing <code >doSomething</code> to the thread <code >object</code>. Only after <code >object</code>'s
construction has completed <code >doSomething</code> is started in the separate thread.
<p>
<li> Exceptions thrown from the thread (e.g., by the function defining the
thread's actions) are local to the executed thread. Either they must be caught
by the executing thread (as each running thread has its own execution stack),
or they can be passed to the starting thread using a <code >packaged_task</code> and a
<code >future</code> (cf., respectively, sections <a href="cplusplus20.html#PACKAGE">20.11</a> and <a href="cplusplus20.html#FUTURE">20.8</a>).
    </ul>
<p>
A thread ends when the function executing a thread finishes. When a
<code >thread</code> object is destroyed while its thread function is still running,
<code >terminate</code> is called, aborting the program's end. Bad news: the destructors
of existing objects aren't called and exceptions that are thrown are left
uncaught. This happens in the following program as the thread is still active
when <code >main</code> ends:
        <pre>
    #include &lt;iostream&gt;
    #include &lt;thread&gt;

    void hello()
    {
        while (true)
            std::cout &lt;&lt; "hello world!\n";
    }

    int main()
    {
        std::thread hi(hello);
    }
</pre>
    There are several ways to solve this problem. One of them is discussed in
the next section.
<p>
<a name="l496"></a>
<h4>20.1.2.1: Static data and threads: thread_local</h4>
        With multi-threaded programs the well-known distinction between global and
local data is somewhat too coarse. For single- and multi-threaded programs
alike, global data are available to all of the program's code, and local data
are available to the function (or compound statement) in which the local data
are defined. But multi-threaded programs may feel the need for an intermediate
type of data, uniquely available to the different threads.
<p>
The <a name="an2553"></a><code >thread_local</code> keyword provides this intermediate data level. Global
variables declared as <code >thread_local</code> are global within each individual
thread. Each thread owns a copy of the <code >thread_local</code> variables, and may
modify them at will. A <code >thread_local</code> variable in one thread is completely
separated from that variable in another thread. Here is an example:
        <pre>
     1: #include &lt;iostream&gt;
     2: #include &lt;thread&gt;
     3: 
     4: using namespace std;
     5: 
     6: thread_local int t_value = 100;
     7: 
     8: void modify(char const *label, int newValue)
     9: {
    10:     cout &lt;&lt; label &lt;&lt; " before: " &lt;&lt; t_value &lt;&lt; ". Address: " &lt;&lt;
    11:                                                     &amp;t_value &lt;&lt; endl;
    12:     t_value = newValue;
    13:     cout &lt;&lt; label &lt;&lt; " after: " &lt;&lt; t_value &lt;&lt; endl;
    14: }
    15: 
    16: int main()
    17: {
    18:     thread(modify, "first", 50).join();
    19:     thread(modify, "second", 20).join();
    20:     modify("main", 0);
    21: }
</pre>
    <ul>
    <li> At line 6 the <code >thread_local</code> variable <code >t_value</code> is defined. It is
initialized to 100, and that becomes the initial value for each separately
running thread;
<p>
<li> In lines 8 through 14 the function <code >modify</code> is defined. It assigns
a new value to <code >t_value</code>;
<p>
<li> At lines 18 and 19 two threads are started, which are immediately
joining the main thread again. 
<p>
<li> The main thread itself is also a thread, and it directly calls
<code >modify</code>. 
    </ul>
    Running this program shows that each separate thread starts with
<code >t_value</code> being 100, and then modifies it without affecting the values of
<code >t_value</code> used by other threads. 
<p>
Note that, although the <code >t_value</code> variables are unique to each thread,
identical addresses may be shown for them. Since each thread uses its own
stack, these variables may occupy the same relative locations within their
respective stacks, giving the illusion that their physical addresses are
identical.
<p>
<a name="l497"></a>
<h4>20.1.2.2: Exceptions and join()</h4>
        Once a thread starts and it isn't detached it must eventually join
its starting (parent) thread, or the program aborts. Usually, once a thread
has started the parent thread continues to do some work by itself:
        <pre>
    void childActions();
    void doSomeWork();

    void parent()
    {
        thread child(childActions);
        doSomeWork();
        child.join();
    }
</pre>
<p>
However, maybe <code >doSomeWork</code> can't complete its work, and throws an
exception, to be caught outside of <code >parent</code>. This, unfortunately, ends
<code >parent</code>, and <code >child.join()</code> is missed. Consequently, the program aborts
because of a thread that hasn't been joined.
<p>
Clearly, all exceptions must be caught, <code >join</code> must be called, and the
exception must be rethrown. But <code >parent</code> cannot use a function try-block, as
the thread object is already out of scope once execution reaches the matching
<code >catch</code>-clause. So we get:
        <pre>
    void childActions();
    void doSomeWork();

    void parent()
    {
        thread child(childActions);
        try
        {
            doSomeWork();
            child.join();
        }
        catch (...)
        {
            child.join();
            throw;
        }
    }
</pre>
<p>
This is ugly: suddenly the function's code is clobbered with a
<code >try-catch</code> clause, as well as some unwelcome code-duplication.
<p>
This situation can be avoided using object based programming. Like, e.g.,
unique pointers, which use their destructors to encapsulate the destruction of
dynamically allocated memory, we can use a comparable technique to encapsulate
thread joining in an object's destructor.
<p>
By defining the <code >thread</code> object inside a class we're sure that by the time
the our object goes out of scope, even if the <code >childActions</code> function
throws an exception, the thread's <code >join</code> member is called. Here are the bare
essentials of our <code >JoinGuard</code> class, providing the join-guarantee (using
in-line member implementations for brevity):
        <pre>
     1: #include &lt;thread&gt;
     2: 
     3: class JoinGuard
     4: {
     5:     std::thread d_thread;
     6: 
     7:     public:
     8:         JoinGuard(std::thread &amp;&amp;threadObj)
     9:         :
    10:             d_thread(std::move(threadObj))
    11:         {}
    12:         ~JoinGuard()
    13:         {
    14:             if (d_thread.joinable())
    15:                 d_thread.join();
    16:         }
    17: };
</pre>
    <ul>
    <li> At line 8 its only constructor starts: it receives a temporary
<code >thread</code> object, which is moved, in line 10, to <code >JoinGuard's d_thread</code>
data member. 
<p>
<li> When the <code >JoinGuard</code> object ceases to exist, its destructor (line
12) makes sure the thread is joined if it's still joinable (lines 14 and 15).
    </ul>
    Here is an example how <code >JoinGuard</code> could be used:
        <pre>
     1: #include &lt;iostream&gt;
     2: #include "joinguard.h"
     3: 
     4: void childActions();
     5: 
     6: void doSomeWork()
     7: {
     8:     throw std::runtime_error("doSomeWork throws");
     9: }
    10: 
    11: void parent()
    12: {
    13:     JoinGuard{std::thread{childActions}};
    14:     doSomeWork();
    15: }
    16: 
    17: int main()
    18: try
    19: {
    20:     parent();
    21: }
    22: catch (std::exception const &amp;exc)
    23: {
    24:     std::cout &lt;&lt; exc.what() &lt;&lt; '\n';
    25: }
</pre>
    <ul>
    <li> At line 4 <code >childActions</code> is declared. Its implementation (not
provided here) defines the child thread's actions.
<p>
<li> The <code >main</code> function (lines 17 through 25) provides the function 
try-block to catch the exception thrown by <code >parent</code>;
<p>
<li> The <code >parent</code> function defines (line 13) an anonymous <code >JoinGuard</code>,
receiving  an anonymous <code >thread</code> object. Anonymous objects are used, as the
parent function doesn't need to access them anymore.
<p>
<li> In line 14 <code >doSomeWork</code> is called, which throws an exception. This
ends <code >parent</code>, but just before that <code >JoinGuard's</code> destructor makes sure
that the child-thread has been joined.
    </ul>
<p>
<a name="MUTEX"></a><a name="l498"></a>
<h2 >20.2: Synchronization (mutexes)</h2>
Objects of <a name="an2554"></a>mutex classes are used to protect shared data.
<p>
Before using mutexes the <a name="an2555"></a><code >&lt;mutex&gt;</code> header file must be included.
<p>
One of the key characteristics of multi-threaded programs is that threads may
share data. Functions running as separate threads have access to all global
data, and may also share the local data of their parent threads. However,
unless proper measures are taken, this may easily result in data corruption,
as illustrated by the following simulation of some steps that could be
encountered in a multi-threaded program:
        <pre>
---------------------------------------------------------------------------
Time step:    Thread 1:     var        Thread 2:       description
---------------------------------------------------------------------------
    0                        5
    1           starts                                  T1 active
    2           writes var                              T1 commences writing
    3           stopped                                 Context switch
    4                                   starts          T2 active
    5                                   writes var      T2 commences writing
    6                       10          assigns 10      T2 writes 10
    7                                   stopped         Context switch
    8           assigns 12                              T1 writes 12
    9                       12
----------------------------------------------------------------------------
</pre>
<p>
In this example, threads 1 and 2 share variable <code >var</code>, initially having
the value 5. At step 1 thread 1 starts, and starts to write a value into
<code >var</code>. However, it is interrupted by a context switch, and thread 2 is
started (step 4). Thread 2 <em >also</em> wants to write a value into <code >var</code>, and
succeeds until time step 7, when another context switch takes place. By now
<code >var</code> is 10. However, thread 1 was also in the process of writing a value
into <code >var</code>, and it is given a chance to complete its work: it assigns 12
to <code >var</code> in time step 8. Once time step 9 is reached, thread 2 proceeds on
the (erroneous) assumption that <code >var</code> must be equal to 10. Clearly, from the
point of view of thread 2 its data have been corrupted.
<p>
In this case data corruption was caused by multiple threads accessing the same
data in an uncontrolled way. To prevent this from happening, access to shared
data should be protected in such a way that only one thread at a time may
access the shared data.
<p>
<em >Mutexes</em> are used to prevent the abovementioned kinds of problems by
offering a guarantee that data are only accessed by the thread that could lock
the mutex that is used to synchronize access to those data.
<p>
Exclusive data access completely depends on cooperation between the
threads. If thread 1 uses mutexes, but thread 2 doesn't, then thread 2 may
freely access the common data. Of course that's bad practice, which should be
avoided.
<p>
It is stressed that although <em >using</em> mutexes is the programmer's
responsibility, their <em >implementation</em> isn't: mutexes offer the necessary
atomic calls. When requesting a mutex-lock the thread is blocked (i.e., the
mutex statement does not return) until the lock has been obtained by the
requesting thread.
<p>
Apart from the class <code >std::mutex</code> the class <a name="an2556"></a>
<code >std::recursive_mutex</code> is available.  When a <code >recursive_mutex</code> is called
multiple times by the same thread it increases its lock-count. Before other
threads may access the protected data the recursive mutex must be unlocked
again that number of times. Moreover, the classes 
        <a name="an2557"></a><code >std::timed_mutex</code> 
    and 
        <a name="an2558"></a><code >std::recursive_timed_mutex</code> 
    are available. Their locks expire when released, but also after a certain
amount of time.
<p>
The members of the mutex classes perform <a name="an2559"></a><em >atomic actions</em>: no context
switch occurs while they are active. So when two threads are trying to
<em >lock</em> a mutex only one can succeed. In the above example: if both threads
would use a mutex to control access to <code >var</code> thread 2 would not have been
able to assign 12 to <code >var</code>, with thread 1 assuming that its value was 10. We
could even have two threads running purely parallel (e.g., on two separate
cores). E.g.:
        <pre>
-------------------------------------------------------------------------
Time step:    Thread 1:        Thread 2:        escription
-------------------------------------------------------------------------
    1         starts           starts           T1 and T2 active
    2         locks            locks            Both threads try to 
                                                lock the mutex
    3         blocks...        obtains lock     T2 obtains the lock,
                                                and T1 must wait
    4         (blocked)        processes var    T2 processes var,
                                                T1 still blocked
    5         obtains lock     releases lock    T2 releases the lock,
                                                and T1 immediately 
                                                obtains the lock
    6         processes var                     now T1 processes var
    7         releases lock                     T1 also releases the lock
-------------------------------------------------------------------------
</pre>
<p>
Although mutexes can directly be used in programs, this rarely happens. It is
more common to embed mutex handling in locking classes that make sure that the
mutex is automatically unlocked again when the mutex lock is no longer
needed. Therefore, this section merely offers an overview of the interfaces of
the mutex classes. Examples of their use will be given in the upcoming
sections (e.g., section <a href="cplusplus20.html#LOCKS">20.3</a>).
<p>
All mutex classes offer the following constructors and members:
    <ul>
    <li><code >mutex() constexpr</code>:<br/>The default <code >constexpr</code> constructor is the only available
constructor; 
<p>
<li><code >~mutex()</code>:<br/>The destructor does <em >not</em> unlock a locked mutex. If locked it must
explicitly be unlocked using the mutex's <code >unlock</code> member;
<p>
<li><a name="an2560"></a><code >void lock()</code>:<br/>The calling thread blocks until it owns the mutex. Unless <code >lock</code> is
called for a recursive mutex a <em >system_error</em> is thrown if the thread
already owns the lock. Recursive mutexes increment their internal 
    <a name="an2561"></a><em >lock count</em>;
<p>
<li><a name="an2562"></a><code >bool try_lock() noexcept</code>:<br/>The calling thread tries to obtain ownership of the mutex. If
ownership is obtained, <code >true</code> is returned, otherwise <code >false</code>. If the
calling thread already owns the lock <code >true</code> is also returned, and in this
case a recursive mutex also increments its internal <a name="an2563"></a><em >lock count</em>;
<p>
<li><a name="an2564"></a><code >void unlock() noexcept</code>:<br/>The calling thread releases ownership of the mutex.  A
<code >system_error</code> is thrown if the thread does not own the
lock. A recursive mutex decrements its interal lock count, releasing
ownership of the mutex once the lock count has decayed to zero;
    </ul>
<p>
The timed-mutex classes (<code >timed_mutex, recursive_timed_mutex</code>) also offer
these members:
    <ul>
    <li><a name="an2565"></a><code >bool try_lock_for(chrono::duration&lt;Rep, Period&gt; const 
            &amp;relTime) noexcept</code>:<br/>The calling thread tries to obtain ownership of the mutex within the
specified time interval. If ownership is obtained, <code >true</code> is returned,
otherwise <code >false</code>. If the calling thread already owns the lock <code >true</code> is
also returned, and in this case a recursive timed mutex also increments its
internal <a name="an2566"></a><em >lock count</em>. The <code >Rep</code> and <code >Duration</code> types are inferred from
the actual <code >relTime</code> argument. E.g.,
       <pre>
std::timed_mutex timedMutex;
timedMutex.try_lock_for(chrono::seconds(5));
</pre>
<p>
<li><a name="an2567"></a><code >bool try_lock_until(chrono::time_point&lt;Clock,
            Duration&gt; const &amp;absTime) noexcept</code>:<br/>The calling thread tries to obtain ownership of the mutex until
<code >absTime</code> has passed. If ownership is obtained, <code >true</code> is returned,
otherwise <code >false</code>. If the calling thread already owns the lock <code >true</code> is
also returned, and in this case a recursive timed mutex also increments its
internal <a name="an2568"></a><em >lock count</em>. The <code >Clock</code> and <code >Duration</code> types are inferred
from the actual <code >absTime</code> argument. E.g.,
       <pre>
std::timed_mutex timedMutex;
timedMutex.try_lock_until(chrono::system_clock::now() + chrono::seconds(5));
</pre>
<p>
</ul>
<p>
<a name="l499"></a>
<h3 >20.2.1: Initialization in multi-threaded programs</h3>
    Before using the <a name="an2569"></a><code >std::once_flag</code> and the
<a name="an2570"></a><code >std::call_once</code> function, introduced in this section, the
<a name="an2571"></a><code >&lt;mutex&gt;</code> header file must be included.
<p>
In single threaded programs the initialization of global data does not
necessarily occur at one point in code. An example is the initialization of
the object of a singleton class (cf. <em >Gamma et al.</em> (1995), Design Patterns,
Addison-Wesley). Singleton classes may define a single static pointer data
member <code >Singleton *s_object</code>, pointing to the singleton's object, and may
offer a static member <code >instance</code>, implemented something like this:
        <pre>
    Singleton &amp;Singleton::instance()
    {
        return s_object ? 
                    s_object 
                : 
                    (s_object = new Singleton);
    }
</pre>
<p>
With multi-threaded programs this approach immediately gets complex. For
example, if two threads call <code >instance</code> at the same time, while <code >s_object</code>
still equals 0, then both may call <code >new Singleton</code>, resulting in one
dynamically allocated <code >Singleton</code> object becoming unreachable. Other
threads, called after <code >s_object</code> was initialized for the first time, may
either return a reference to that object, or may return a reference to the
object initialized by the second thread. Not exactly the expected behavior of
a singleton.
<p>
Mutexes (cf. section <a href="cplusplus20.html#MUTEX">20.2</a>) can be used to solve these kinds of problems,
but they result in some overhead and inefficiency, as the mutex must be
inspected at each call of <code >Singleton::instance</code>. 
<p>
When variables must dynamically be initialized, and the initialization should
take place only once the <code >std::once_flag</code> type and the <code >std::call_once</code>
function should be used.
<p>
The <code >call_once</code> function expects two or three arguments:
    <ul>
    <li>  The first argument is a <code >once_flag</code> variable, keeping track of the
actual initialization status. The <code >call_once</code> function simply returns if
the <code >once_flag</code> indicates that initialization already took place;
<p>
<li> The second argument is the address of a function which must be called
only once. This function may be a free function or it may be the address of a
class member function;
<p>
<li> If the second argument is the address of a class member function,
then the object for which the member function should be called must be
provided as <code >call_once's</code> third argument.
    </ul>
    A thread-safe implementation of the singleton's <code >instance</code> function can
now easily be designed (using in-class implementations for brevity):
        <pre>
    class Singleton
    { 
        static std::once_flag s_once;
        static Singleton *s_singleton;
        ...
        public:
            static Singleton *instance()
            {
                std::call_once(s_once, []{s_singleton = new Singleton;} );
                return s_singleton;
            }
        ...
    };
</pre>
<p>
However, there are additional ways to initialize data, even for multi-threaded programs:
    <ul>
    <li> First, suppose a constructor is declared with the <a name="an2572"></a><code >constexpr</code>
keyword (cf. section <a href="cplusplus08.html#CONSTEXPR">8.1.4.1</a>), satisfying the requirements for constant
initialization. In this case, a static object, initialized using that
constructor, is guaranteed to be initialized before any code is run as part of
the static initialization phase. This is used by <code >std::mutex</code>, as it
eliminates the possibility of race conditions when global mutexes are
initialized.
<p>
<li> Second, a static variable defined within a compound statement may be
used (e.g., a static local variable within a function body).  Static
variables <a name="an2573"></a> defined within a compound
statement are initialized the first time the function is called at the point
in the code where the static variable is defined. Here is an example:
        <pre>
        #include &lt;iostream&gt;

        struct Cons
        {
            Cons()
            {
                std::cout &lt;&lt; "Cons called\n";
            }
        };
        void called(char const *time)
        {
            std::cout &lt;&lt; time &lt;&lt; "time called() activated\n";
            static Cons cons;
        }
        int main()
        {
            std::cout &lt;&lt; "Pre-1\n";
            called("first");
            called("second");
            std::cout &lt;&lt; "Pre-2\n";
            Cons cons;
        }
    /*
        Displays:
            Pre-1
            firsttime called() activated
            Cons called
            secondtime called() activated
            Pre-2
            Cons called
    */
</pre>
    This feature causes a thread to wait automatically if another thread is
still initializing the static data (note that <em >non-static</em> data never cause
problems, as non-static local variables only exist within their own thread of
execution).
    </ul>
<p>
<a name="l500"></a>
<h3 >20.2.2: Shared mutexes</h3>
    Shared mutexes (via the type <code >std::shared_mutex</code>) are available after
including the <a name="an2574"></a><code >&lt;shared_mutex&gt;</code> header file.  Shared mutex types behave like
<code >timed_mutex</code> types and optionally have the characteristics described below.
<p>
The class <code >shared_mutex</code> provides a non-recursive mutex with shared
ownership semantics, comparable to, e.g., the <code >shared_ptr</code> type.
A program using <code >shared_mutexes</code> is undefined if:
    <ul>
    <li> it destroys a shared_mutex object owned by any thread;
    <li> a thread recursively attempts to gain ownership of a
        <code >shared_mutex</code>;   
    <li> a thread terminates while owning a <code >shared_mutex</code>.
    </ul>
<p>
Shared mutex types provide a shared lock ownership mode. Multiple threads can
simultaneously hold a shared lock ownership of a <code >shared_mutex</code> type of
object. But no thread can hold a shared lock while another thread holds an
exclusive lock on the same <code >shared_mutex</code> object, and vice-versa.
<p>
The type <code >shared_mutex</code> offers the following members:
    <ul>
    <li><a name="an2575"></a><code >void lock_shared()</code>:<br/>Blocks the calling thread until shared ownership of the mutex can be
obtained by the calling thread. An exception is thrown if the current thread
already owns the lock, if it is not allowed to lock the mutex, or if the mutex
is already locked and blocking is not possible;
<p>
<li><a name="an2576"></a><code >void unlock_shared()</code>:<br/>Releases a shared lock on the mutex held by the calling thread. Nothing
happens if the current thread does not already own the lock;
<p>
<li><a name="an2577"></a><code >bool try_lock_shared()</code>:<br/>The current thread attempts to obtain shared ownership of the mutex
without blocking. If shared ownership is not obtained, there is no effect and
<code >try_lock_shared</code> immediately returns.  Returns <code >true</code> if the shared
ownership lock was acquired, <code >false</code> otherwise.  An implementation may fail
to obtain the lock even if it is not held by any other thread. Initially the
calling thread may not yet own the mutex;
<p>
<li><a name="an2578"></a><code >bool try_lock_shared_for(rel_time)</code>:<br/>Attempts to obtain shared lock ownership for the calling thread within
the relative time period specified by <code >rel_time</code>. If the time specified by
<code >rel_time</code> is less than or equal to <code >rel_time.zero()</code>, the member attempts
to obtain ownership without blocking (as if by calling
<code >try_lock_shared()</code>). The member shall return within the time interval
specified by <code >rel_time</code> only if it has obtained shared ownership of the mutex
object.  Returns <code >true</code> if the shared ownership lock was acquired, <code >false</code>
otherwise. Initially the calling thread may not yet own the mutex;
<p>
<li><a name="an2579"></a><code >bool try_lock_shared_until(abs_time)</code>:<br/>Attempts to obtain shared lock ownership for the calling thread until the
time specified by <code >abs_time</code> has passed. If the time specified by
<code >abs_time</code> has already passed then the member attempts to obtain ownership
without blocking (as if by calling <code >try_lock_shared()</code>).  Returns <code >true</code>
if the shared ownership lock was acquired, <code >false</code> otherwise. Initially the
calling thread may not yet own the mutex;
    </ul>
<p>
<a name="LOCKS"></a><a name="l501"></a>
<h2 >20.3: Locks and lock handling</h2>
Locks are used to simplify the use of mutexes. Before locks can be used the
<a name="an2580"></a><code >&lt;mutex&gt;</code> header file must be included.
<p>
Whenever threads share data, and at least one of the threads may change common
data, mutexes should be used to prevent threads from using the same data
synchronously.
<p>
Usually locks are released at the end of action blocks. This requires explicit
calls to the mutexes' <code >unlock</code> function, which introduces comparable
problems as we've seen with the thread's <code >join</code> member.
<p>
To simplify locking and unlocking two mutex wrapper classes are available:
    <ul>
    <li><a name="an2581"></a><code >std::lock_guard</code>:<br/>objects of this class offer the basic unlock-guarantee: their
destructors call the member <code >unlock</code> of the mutexes they control;
<p>
<li><a name="an2582"></a><code >std::unique_lock</code>:<br/>objects of this class offer a more extensive interface, allowing
explicit unlocking and locking of the mutexes they control, while their
destructors preserve the unlock-guarantee also offered by <code >lock_guard</code>;
    </ul>
<p>
The class <code >lock_guard</code> offers a limited, but useful interface:
    <ul>
<p>
<li><code >lock_guard&lt;Mutex&gt;(Mutex &amp;mutex)</code>:<br/>when defining a <code >lock_guard</code> object the mutex type (e.g.,
<code >std::mutex, std::timed_mutex, std::shared_mutex</code>) is specified, and a mutex
of the indicated type is provided as its argument. The construction blocks
until the <code >lock_guard</code> object owns the lock. The <code >lock_guard's</code> destructor
automatically releases the mutex lock.
<p>
<li><code >lock_guard&lt;Mutex&gt;(Mutex &amp;mutex, std::adopt_lock_t)</code>:<br/>this constructor is used to transfer control over the mutex from the
calling thread to the <code >lock_guard</code>.  The mutex lock is released again by the
<code >lock_guard's</code> destructor. At construction time the mutex must already be
owned by the calling thread. Here is an illustration of how it can be used:
        <pre>
 1: void threadAction(std::mutex &amp;mut, int &amp;sharedInt)
 2: {
 3:     std::lock_guard&lt;std::mutex&gt; lg{mut, std::adopt_lock_t()};
 4:     // do something with sharedInt
 5: }
</pre>
            <ul>
            <li> At line 1 <code >threadAction</code> receives a reference to a
mutex. Assume the mutex owns the lock;
<p>
<li> At line 3 control is transferred to the <code >lock_guard</code>. Even
though we don't explicitly use the <code >lock_guard</code> object, an object should be
defined to prevent the compiler from destroying an anonymous object before the
function ends;
<p>
<li> When the function ends, at line 5, the mutex's lock is
released by the <code >lock_guard's</code> destructor.
            </ul>
<p>
<li><code >mutex_type</code>:<br/>in <a name="an2583"></a> addition to the constructors and destructor,
<code >lock_guard&lt;Mutex&gt;</code> types also define the type <a name="an2584"></a><code >mutex_type</code>: it is a
synonym of the <code >Mutex</code> type that is passed to the <code >lock_guard</code>'s
constructor.
    </ul>
<p>
Here is a simple example of a multi-threaded program using <code >lock_guards</code>
to prevent information inserted into <code >cout</code> from getting mixed.
        <pre>
    bool oneLine(istream &amp;in, mutex &amp;mut, int nr)
    {
       lock_guard&lt;mutex&gt; lg(mut);
    
        string line;
        if (not getline(in, line))
            return false;
    
        cout &lt;&lt; nr &lt;&lt; ": " &lt;&lt; line &lt;&lt; endl;
    
        return true;
    }
    
    void io(istream &amp;in, mutex &amp;mut, int nr)
    {
        while (oneLine(in, mut, nr))
            this_thread::yield();
    }
    
    int main(int argc, char **argv)
    {
        ifstream in(argv[1]);
        mutex ioMutex;
    
        thread t1(io, ref(in), ref(ioMutex), 1);
        thread t2(io, ref(in), ref(ioMutex), 2);
        thread t3(io, ref(in), ref(ioMutex), 3);
    
        t1.join();
        t2.join();
        t3.join();
    }
</pre>
<p>
As with <code >lock_guard</code>, a mutex-type must be specified when defining
objects of the class <a name="an2585"></a><code >std::unique_lock</code>.  The class
<code >unique_lock</code> is much more elaborate than the basic <code >lock_guard</code> class
template.  Its interface does not define a copy constructor or overloaded
assignment operator, but it <em >does</em> define a move constructor and a move
assignment operator. In the following overview of <code >unique_lock</code>'s inteface
<code >Mutex</code> refers to the mutex-type that is specified when defining a
<code >unique_lock</code>:
    <ul>
    <li><code >unique_lock() noexcept</code>:<br/>the default constructor is not yet associated with a <code >mutex</code>
object. It must be assigned a <code >mutex</code> (e.g., using move-assignment) before
it can do anything useful;
<p>
<li><code >explicit unique_lock(Mutex &amp;mutex)</code>:<br/>initializes a <code >unique_lock</code> with an existing <code >Mutex</code> object, and
calls <code >mutex.lock()</code>;
<p>
<li><code >unique_lock(Mutex &amp;mutex, defer_lock_t) noexcept</code>:<br/>initializes a <code >unique_lock</code> with an existing <code >Mutex</code> object, but
does not call <code >mutex.lock()</code>. Call it by passing a <code >defer_lock_t</code> object
as the constructor's second argument, e.g.,
            <pre>
unique_lock&lt;mutex&gt; ul(mutexObj, defer_lock_t())
</pre>
<p>
<li><code >unique_lock(Mutex &amp;mutex, try_to_lock_t) noexcept</code>:<br/>initializes a <code >unique_lock</code> with an existing <code >Mutex</code> object, and
calls <code >mutex.try_lock()</code>: the constructor won't block if the mutex cannot be
locked;
<p>
<li><code >unique_lock(Mutex &amp;mutex, adopt_lock_t) noexcept</code>:<br/>initializes a <code >unique_lock</code> with an existing <code >Mutex</code> object,
and assumes that the current thread has already locked the mutex;
<p>
<li><code >unique_lock(Mutex &amp;mutex, chrono::duration&lt;Rep, Period&gt; const
        &amp;relTime) noexcept</code>:<br/>this constructor tries to obtain ownership of the <code >Mutex</code> object by
calling <code >mutex.try_lock_for(relTime)</code>. The specified mutex type must
therefore support this member (e.g., it is a <code >std::timed_mutex</code>). It could
be called like this:
           <pre>
std::unique_lock&lt;std::timed_mutex&gt; ulock(timedMutex, 
                                         std::chrono::seconds(5));
</pre>
<p>
<li><code >unique_lock(Mutex &amp;mutex, chrono::time_point&lt;Clock, Duration&gt; const
        &amp;absTime) noexcept</code>:<br/>this constructor tries to obtain ownership of the <code >Mutex</code> object by
calling <code >mutex.try_lock_until(absTime)</code>. The specified mutex type must
therefore support this member (e.g., it is a <code >std::timed_mutex</code>). 
This constructor could be called like this:
            <pre>
std::unique_lock&lt;std::timed_mutex&gt; ulock(
                timedMutex, 
                std::chrono::system_clock::now() + std::chrono::seconds(5)
            );
</pre>
<p>
<li><a name="an2586"></a><code >void lock()</code>:<br/>blocks the current thread until ownership of the mutex that is managed
by the <code >unique_lock</code> is obtained. If no mutex is currently managed, then a
<code >system_error</code> exception is thrown.
<p>
<li><a name="an2587"></a><code >Mutex *mutex() const noexcept</code>:<br/>returns a pointer to the mutex object stored inside the
<code >unique_lock</code> (a <code >nullptr</code> is returned if no mutex object is currently
associated with the <code >unique_lock</code> object.)
<p>
<li><code >explicit operator bool() const noexcept</code>:<br/>returns <code >true</code> if the <code >unique_lock</code> owns a locked mutex, otherwise
<code >false</code> is returned;
<p>
<li><code >unique_lock&amp; operator=(unique_lock &amp;&amp;tmp) noexcept</code>:<br/>if the left-hand operand owns a lock, it will call its mutex's
<code >unlock</code> member, whereafter <code >tmp's</code> state is transferred to the left-hand
operand;
<p>
<li><a name="an2588"></a><code >bool owns_lock() const noexcept</code>:<br/>returns <code >true</code> if the <code >unique_lock</code> owns the mutex, otherwise
<code >false</code> is returned;
<p>
<li><a name="an2589"></a><code >Mutex *release() noexcept</code>:<br/>returns a pointer to the mutex object that is associated with the
<code >unique_lock</code> object, discarding that association;
<p>
<li><a name="an2590"></a><code >void swap(unique_lock&amp; other) noexcept</code>:<br/>swaps the states of the current <code >unique_lock</code> and <code >other</code>;
<p>
<li><a name="an2591"></a><code >bool try_lock()</code>:<br/>tries to obtain ownership of the mutex that is associated witg the
<code >unique_lock</code>, returning <code >true</code> if this succeeds, and <code >false</code>
otherwise. If no mutex is currently associated with the <code >unique_lock</code>
object, then a <code >system_error</code> exception is thrown;
<p>
<li><a name="an2592"></a><code >bool try_lock_for(chrono::duration&lt;Rep, Period&gt; const
        &amp;relTime)</code>:<br/>this member function tries to obtain ownership of the <code >Mutex</code> object
managed by the <code >unique_lock</code> object by calling the mutex's
<code >try_lock_for(relTime)</code> member. The specified mutex type must therefore
support this member (e.g., it is a <code >std::timed_mutex</code>);
<p>
<li><a name="an2593"></a><code >bool try_lock_until(chrono::time_point&lt;Clock,
        Duration&gt; const &amp;absTime)</code>:<br/>this member function tries to obtain ownership of the <code >Mutex</code> object
managed by the <code >unique_lock</code> object by calling the mutex's
<code >mutex.try_lock_until(absTime)</code> member. The specified mutex type must
therefore support this member (e.g., it is a <code >std::timed_mutex</code>);
<p>
<li><a name="an2594"></a><code >void unlock()</code>:<br/>releases ownership of the mutex (or reduces the mutex's lock count). A
<code >system_error</code> exception is thrown if the <code >unique_lock</code> object does not
own the mutex.
    </ul>
<p>
In addition to the members of the classes <code >std::lock_guard</code> and
<code >std::unique_lock</code> the functions <code >std::lock</code><a name="an2595"></a> and
<code >std::try_lock</code><a name="an2596"></a> are available. These functions can be
used to prevent <em >deadlocks</em>, the topic of the next section.
<p>
<a name="l502"></a>
<h3 >20.3.1: Deadlocks</h3>
    A deadlock occurs when two locks are required to process data, but one thread
obtains the first lock and another thread obtains the second lock. <strong >C++</strong>
defines the generic
    <a name="an2597"></a><code >std::lock</code> and <a name="an2598"></a><code >std::try_lock</code> functions that can
be used to help preventing such situations.
<p>
Before these functions  can be used the <a name="an2599"></a><code >&lt;mutex&gt;</code> header file must be
included
<p>
In the following overview <code >L1 &amp;l1, ...</code> represents one or more
references to objects of lockable types:
    <ul>
    <li><code >void std::lock(L1 &amp;l1, ...)</code>:<br/>When the function returns locks were obtained on all <code >li</code>
        objects. If a lock could not be obtained for at least one of the
        objects, then all locks obtained so far are relased, even if the
        object for which no lock could be obtained threw an exception;
    <li><code >int std::try_lock(L1 &amp;l1, ...)</code>:<br/>This function calls the lockable objects' <code >try_lock</code> members. If all
        locks could be obtained, then -1 is returned. Otherwise the (0-based)
        index of the first argument which could not be locked is returned,
        releasing all previously obtained locks.
    </ul>
<p>
As an example consider the following little multi-threaded program: The
threads use mutexes to obtain unique access to <code >cout</code> and to an <code >int
value</code>. However, <code >fun1</code> first locks <code >cout</code> (line 7), and then <code >value</code>
(line 10); <code >fun2</code> first locks <code >value</code> (line 16) and then <code >cout</code> (line
19). Clearly, if <code >fun1</code> has locked <code >cout</code> <code >fun2</code> can't obtain the lock
until <code >fun1</code> has released it. Unfortunately, <code >fun2</code> has locked <code >value</code>,
and the functions only release their locks when returning. But in order to
access the information in <code >value</code> <code >fun1</code> it must have obtained a lock on
<code >value</code>, which it can't, as <code >fun2</code> has already locked <code >value</code>: the
threads are waiting for each other, and neither thread gives in.
        <pre>
     1: 
     2: int value;
     3: mutex valueMutex;
     4: mutex coutMutex;
     5: 
     6: void fun1()
     7: {
     8:     lock_guard&lt;mutex&gt; lg1(coutMutex);
     9:     cout &lt;&lt; "fun 1 locks cout\n";
    10: 
    11:     lock_guard&lt;mutex&gt; lg2(valueMutex);
    12:     cout &lt;&lt; "fun 1 locks value\n";
    13: }
    14: 
    15: void fun2()
    16: {
    17:     lock_guard&lt;mutex&gt; lg1(valueMutex);
    18:     cerr &lt;&lt; "fun 2 locks value\n";
    19: 
    20:     lock_guard&lt;mutex&gt; lg2(coutMutex);
    21:     cout &lt;&lt; "fun 2 locks cout\n";
    22: }
    23: 
    24: int main()
    25: {
    26:     thread t1(fun1);
    27:     fun2();
    28:     t1.join();
    29: }
    30: 
</pre>
<p>
A good recipe for avoiding deadlocks is to prevent nested (or multiple) mutex
lock calls. But if multiple mutexes must be used, always obtain the locks in
the same order. Rather than doing this yourself, <code >std::lock</code> and
<code >std::try_lock</code> should be used whenever possible to obtain multiple mutex
locks. These functions accept multiple arguments, which must be lockable types
like <code >lock_guard, unique_lock,</code> or even a plain <code >mutex</code>. The previous
deadlocking program, can be modified to call <code >std::lock</code> to lock both
mutexes. In this example using one single mutex would also work, but the
modified program now looks as similar as possible to the previous
program. Note how in lines 10 and 21 a different
ordering of the <code >unique_locks</code> arguments was used: it is not necessary to
use an identical argument order when calling <code >std::lock</code> or
<code >std::try_lock</code>. 
        <pre>
     1: 
     2: int value;
     3: mutex valueMutex;
     4: mutex coutMutex;
     5: 
     6: void fun1()
     7: {
     8:     unique_lock&lt;mutex&gt; lg1(coutMutex, defer_lock);
     9:     unique_lock&lt;mutex&gt; lg2(valueMutex, defer_lock);
    10: 
    11:     lock(lg1, lg2);
    12: 
    13:     cout &lt;&lt; "fun 1 locks cout\n";
    14:     cout &lt;&lt; "fun 1 locks value\n";
    15: }
    16: 
    17: void fun2()
    18: {
    19:     unique_lock&lt;mutex&gt; lg1(coutMutex, defer_lock);
    20:     unique_lock&lt;mutex&gt; lg2(valueMutex, defer_lock);
    21: 
    22:     lock(lg2, lg1);
    23: 
    24:     cout &lt;&lt; "fun 2 locks cout\n";
    25:     cout &lt;&lt; "fun 2 locks value\n";
    26: }
    27: 
    28: int main()
    29: {
    30:     thread t1(fun1);
    31:     thread t2(fun2);
    32:     t1.join();
    33:     t2.join();
    34: }
    35: 
</pre>
<p>
<a name="l503"></a>
<h3 >20.3.2: Shared locks</h3>
    <em >Shared locks</em> are available through the type
    <a name="an2600"></a><code >std::shared_lock</code>, after including the
    <a name="an2601"></a><code >&lt;shared_mutex&gt;</code> header file.
<p>
An object of the type <code >std::shared_lock</code> controls the shared ownership of a
lockable object within a scope. Shared ownership of the lockable object may be
acquired at construction time or thereafter, and once acquired, it may be
transferred to another <code >shared_lock</code> object. Objects of type <code >shared_lock</code>
cannot be copied, but move construction and assignment is supported. 
<p>
The behavior of a program is undefined if the contained pointer to a mutex
(<code >pm</code>) has a non-zero value and the lockable object pointed to by <code >pm</code> does
not exist for the entire remaining lifetime of the <code >shared_lock</code>
object. The supplied mutex type must be a <code >shared_mutex</code> or a type having
the same characteristics.
<p>
The type <code >shared_lock</code> offers the following constructors, destructor and
operators:
    <ul>
    <li><code >shared_lock() noexcept</code>:<br/>The default constructor creates a <code >shared_lock</code> which is not owned
by a thread and for which <code >pm == 0</code>;
<p>
<li><code >explicit shared_lock(mutex_type &amp;mut)</code>:<br/>This constructor locks the mutex, calling <code >mut.lock_shared()</code>. The
calling thread may not already own the lock. Following the construction <code >pm
== &amp;mut</code>, and the lock is owned by the current thread;
<p>
<li><code >shared_lock(mutex_type &amp;mut, defer_lock_t) noexcept</code>:<br/>This constructor assigns <code >pm</code> to <code >&amp;mut</code>, but the calling thread 
does not own the lock;
<p>
<li><code >shared_lock(mutex_type &amp;mut, try_to_lock_t)</code>:<br/>This constructor tries to locks the mutex, calling
<code >mut.try_lock_shared()</code>. The calling thread may not already own the
lock. Following the construction <code >pm == &amp;mut</code>, and the lock may or may not
be owned by current thread, depending on the return value of
<code >try_lock_shared;</code>
<p>
<li><code >shared_lock(mutex_type &amp;mut, adopt_lock_t)</code>:<br/>This constructor can be called if the calling thread has shared
ownership of the mutex. Following the construction <code >pm == &amp;mut</code>, and the
lock is owned by the current thread;
<p>
<li><code >shared_lock(mutex_type &amp;mut,
                chrono::time_point&lt;Clock, Duration&gt; const &amp;abs_time)</code>:<br/>This constructor is a member template, where <code >Clock</code> and
<code >Duration</code> are types specifying a clock and absolute time (cf. section
<a href="cplusplus04.html#TIMESPEC">4.2</a>). It can be called if the calling thread does not already own
the mutex. It calls <code >mut.try_lock_shared_until(abs_time)</code>. Following the
construction <code >pm == &amp;mut</code>, and the lock may or may not be owned by current
thread, depending on the return value of <code >try_lock_shared_until;</code>
<p>
<li><code >shared_lock(mutex_type &amp;mut, 
                chrono::duration&lt;Rep, Period&gt; const &amp;rel_time)</code>:<br/>This constructor is a member template, where <code >Clock</code> and
<code >Period</code> are types specifying a clock and relative time (cf. section
<a href="cplusplus04.html#TIMESPEC">4.2</a>). It can be called if the calling thread does not already own
the mutex. It calls <code >mut.try_lock_shared_for(abs_time)</code>. Following the
construction <code >pm == &amp;mut</code>, and the lock may or may not be owned by current
thread, depending on the return value of <code >try_lock_shared_for;</code>
<p>
<li><code >shared_lock(shared_lock &amp;&amp;tmp) noexcept</code>:<br/>The move constructor transfers the information in <code >tmp</code> to the
newly constructed <code >shared_lock</code>. Following the construction <code >tmp.pm == 0</code>
and <code >tmp</code> no longer owns the lock;
<p>
<li><code >~shared_lock()</code>:<br/>If the lock is owned by the current thread, 
<code >pm-&gt;unlock_shared()</code> is called;
<p>
<li><code >shared_lock &amp;operator=(shared_lock &amp;&amp;tmp) noexcept</code>
        (The move assignment operator calls <code >pm-&gt;unlock_shared</code> and then
transfers the information in <code >tmp</code> to the
current <code >shared_lock</code> object. Following this <code >tmp.pm == 0</code>
and <code >tmp</code> no longer owns the lock;)
<p>
<li><a name="an2602"></a><code >explicit operator bool () const noexcept</code>:<br/>Returns whether or not the <code >shared_lock</code> object owns the lock.
    </ul>
<p>
The following members are provided:
<p>
<ul>
    <li><a name="an2603"></a><code >void lock()</code>:<br/>Calls <code >pm-&gt;lock_shared()</code>, after which the current tread owns the
shared lock. Exceptions may be thrown from <code >lock_shared</code>, and otherwise if
<code >pm == 0</code> or if the current thread already owns the lock;
<p>
<li><a name="an2604"></a><code >mutex_type *mutex() const noexcept</code>:<br/>Returns <code >pm</code>;
<p>
<li><a name="an2605"></a><code >mutex_type *release() noexcept</code>:<br/>Returns the previous value of <code >pm</code>, which is equal to zero after
calling this member. Also, the current object no longer owns the lock;
<p>
<li><a name="an2606"></a><code >void swap(shared_lock &amp;other) noexcept</code>:<br/>Swaps the data members of the current and the <code >other</code> <code >shared_lock</code>
objects. There is also a free member <code >swap</code>, a function template, swapping
two <code >shared_lock&lt;Mutex&gt;</code> objects, where <code >Mutex</code> represents the mutex type
for which the shared lock objects were instantiated: <code >void
swap(shared_lock&lt;Mutex&gt; &amp;one, shared_lock&lt;Mutex&gt; &amp;two) noexcept</code>;
<p>
<li><a name="an2607"></a><code >bool try_lock()</code>:<br/>Calls <code >pm-&gt;try_lock_shared()</code>, returning this call's return value.
Exceptions may be thrown from <code >try_lock_shared</code>, and
otherwise if <code >pm == 0</code> or if the current thread already owns the lock;
<p>
<li><a name="an2608"></a><code >bool try_lock_for(const chrono::duration&lt;Rep, Period&gt;&amp;
rel_time)</code>:<br/>A member template, where <code >Clock</code> and <code >Period</code> are types specifying a
clock and relative time (cf. section <a href="cplusplus04.html#TIMESPEC">4.2</a>). It calls
<code >mut.try_lock_shared_for(abs_time)</code>. Following the call the lock may or may
not be owned by current thread, depending on the return value of
<code >try_lock_shared_until</code>.  Exceptions may be thrown from
<code >try_lock_shared_for</code>, and otherwise if <code >pm == 0</code> or if the current thread
already owns the lock;
<p>
<li><a name="an2609"></a><code >bool try_lock_until(const chrono::time_point&lt;Clock,
Duration&gt;&amp; abs_time)</code>:<br/>A member template, where <code >Clock</code> and <code >Duration</code> are types specifying
a clock and absolute time (cf. section <a href="cplusplus04.html#TIMESPEC">4.2</a>). It calls
<code >mut.try_lock_shared_until(abs_time)</code>, returning its return value. Following
the call the lock may or may not be owned by current thread, depending on the
return value of <code >try_lock_shared_until</code>.  Exceptions may be thrown from
<code >try_lock_shared_until</code>, and otherwise if <code >pm == 0</code> or if the current
thread already owns the lock;
<p>
<li><a name="an2610"></a><code >void unlock()</code>:<br/>Unlocks the shared mutex lock, releasing its ownership. Throws an
exception if the shared mutex was not owned by the current thread.
    </ul>
<p>
<a name="l504"></a>
<h2 >20.4: Event handling (condition variables)</h2>
This section introduces <em >condition variables</em>. Condition variables allow
programs to synchronize threads using the <em >states</em> of data, rather than
simply locking the <em >access</em> to data (which is realized using mutexes).
<p>
Before condition variables can be used the <a name="an2611"></a><code >&lt;condition_variable&gt;</code> header
file must be included.
<p>
To start our discussion, consider a classic producer-consumer scenario: the
producer generates items which are consumed by a consumer. The producer can
only produce a certain number of items before its storage capacity has filled
up and the client cannot consume more items than the producer has produced.
<p>
At some point the producer's storage capacity has filled to the brim, and the
producer has to wait until the client has at least consumed some items,
thereby creating space in the producer's storage. Similarly, the consumer
cannot start consuming until the producer has at least produced some items.
<p>
Implementing this scenario only using mutexes (data locking) is not an
attractive option, as merely using mutexes forces a program to implement the
scenario using <em >polling</em>: processes must continuously (re)acquire the
mutex's lock, determine whether they can perform some action, followed by the
release of the lock. Often there's no action to perform, and the process is
busy acquiring and releasing the mutex's lock. Polling forces threads to wait
until they can lock the mutex, even though continuation might already be
possible. The polling interval could be reduced, but that too isn't an
attractive option, as that increases the overhead associated with handling the
mutexes (also called `busy waiting').
<p>
Condition variables can be used to prevent polling. Threads can use condition
variables to <em >notify</em> waiting threads that there is something for them to
do. This way threads can synchronize on data values (<em >states</em>).
<p>
As data values may be modified by multiple threads, threads still need to use
mutexes, but only for controlling access to the data.  In addition, condition
variables allow threads to <em >release</em> ownership of mutexes until a certain
value has been obtained, until a preset amount of time has been passed, or
until a preset point in time has been reached.
<p>
The prototypical setup of threads using condition variables looks like this:
    <ul>
    <li> consumer thread(s) act like this:
        <pre>
    lock the mutex
    while the required condition has not yet been attained (i.e., is false):
        wait until being notified 
         (this automatically releasing the mutex's lock).
    once the mutex's lock has been reacquired, and the required condition
    has been attained:
        process the data
    release the mutex's lock.
</pre>
<p>
<li> producer thread(s) act similarly:
        <pre>
    lock the mutex
    while the required condition has not yet been attained:
        do something to attain the required condition
    notify waiting threads (that the required condition has been attained)
    release the mutex's lock.
</pre>
<p>
</ul> 
    No matter which thread starts, the thread holding the mutex's lock will at
some point release the lock, allowing the other process to (re)acquire it. If
the consumer starts it immediately releases the lock once it enters its
waiting state; if the producer starts it releases the lock once the condition
is true. 
<p>
This protocol hides a subtle initial synchronization requirement. The consumer
will miss the producer's notification if it (i.e., the consumer) hasn't yet
entered its waiting state. So <em >waiting (consumer) threads should start
before notifying (producer) threads</em>. Once threads have started, no
assumptions can be made anymore about the order in which any of the condition
variable's members (<code >notify_one, notify_all, wait, wait_for</code>, and
<code >wait_until</code>) are called.
<p>
Condition variables come in two flavors: objects of the class 
    <a name="an2612"></a><code >std::condition_variable</code> are used in combination
with objects of type <code >unique_lock&lt;mutex&gt;</code>. Because of 
optimizations which are available for this specific combination using 
<code >condition_variables</code> is somewhat more efficient than using the more
generally applicable class
    <a name="an2613"></a><code >std::condition_variable_any</code>, which may be
used with any (e.g., user supplied) lock type.
<p>
Condition variable classes (covered in detail in the next two sections) offer
members like <code >wait, wait_for, wait_until, notify_one</code> and <code >notify_all</code>
that may concurrently be called.  The notifying members are always atomically
executed. Execution of the <code >wait</code> members consists of three atomic parts:
    <ul>
    <li> the mutex is released, and the thread is suspended until its
        notification; 
    <li> Once the notification has been received, the lock is reacquired
    <li> The wait state ends (and processing continues beyond the <code >wait</code>
        call). 
    </ul>
    So, returning from <code >wait</code>-members the previously waiting thread 
has reacquired the mutex's lock.
<p>
In addition to the condition variable classes the following free function and
<code >enum</code> type is provided:
    <ul>
    <li><a name="an2614"></a><code >void
        std::notify_all_at_thread_exit(condition_variable &amp;cond,
        unique_lock&lt;mutex&gt; lockObject)</code>:<br/>once the current thread has ended, all other threads waiting on
        <code >cond</code> are notified. It is good practice to exit the thread as
        soon as possible after calling <code >notify_all_at_thread_exit</code>.
<p>
Waiting threads must verify that the thread they were waiting for has
        indeed ended. This is usually realized  by first obtaining the lock on
        <code >lockObject</code>, followed by verifying that the condition
        they were waiting for is true and that the lock was not
        reacquired before <code >notify_all_at_thread_exit</code> was called.
<p>
<li><a name="an2615"></a><code >std::cv_status</code>:<br/>the <code >cv_status</code> enum is used by several member functions of the
        condition variable classes (cf. sections <a href="cplusplus20.html#CONDVAR1">20.4.1</a> and
        <a href="cplusplus20.html#CONDVAR2">20.4.2</a>): 
       <pre>
namespace std
{
    enum class cv_status 
    { 
        no_timeout, 
        timeout 
    };
}
</pre>
<p>
</ul>
<p>
<a name="CONDVAR1"></a><a name="l505"></a>
<h3 >20.4.1: The class std::condition_variable</h3>
    The class <code >std::condition_variable</code><a name="an2616"></a> merely offers a
default constructor. No copy constructor or overloaded assignment operator is
provided.
<p>
Before using the class <code >condition_variable</code> the <a name="an2617"></a><code >&lt;condition_variable&gt;</code>
header file must be included.
<p>
The class's destructor requires that no thread is blocked by the thread
destroying the <code >condition_variable</code>. So all threads waiting on a
<code >condition_variable</code> must be notified before a <code >condition_variable</code>
object's lifetime ends. Calling <code >notify_all</code> (see below) before a
<code >condition_variable's</code> lifetime ends takes care of that, as the
<code >condition_variable's</code> thread releases its lock of the <code >mutex</code> variable,
allowing one of the notified threads to lock the mutex.
<p>
In the following member-descriptions a type <code >Predicate</code> indicates that a
provided <code >Predicate</code> argument can be called as a function without arguments,
returning a <code >bool</code>. Also, other member functions are frequently referred
to. It is tacitly assumed that all member referred to below were called using
the same condition variable object.
<p>
The class <code >condition_variable</code> supports several <code >wait</code> members, which
block the thread until notified by another thread (or after a configurable
waiting time). However, <code >wait</code> members may also spuriously unblock, without
having reacquired the lock. Therefore, returning from <code >wait</code> members threads
should verify that the required condition is actually true. If not,
again calling <code >wait</code> may be appropriate.  The next piece of pseudo code
illustrates this scheme:
       <pre>
    while (conditionNotTrue())
        condVariable.wait(&amp;uniqueLock);
</pre>
<p>
The class <code >condition_variable</code>'s members are:
    <ul>
    <li><a name="an2618"></a><code >void notify_one() noexcept</code>:<br/>one <code >wait</code> member called by other threads returns. Which one
        actually returns cannot be predicted.
<p>
<li><a name="an2619"></a><code >void notify_all() noexcept</code>:<br/>all <code >wait</code> members called by other threads unblock their wait
        states. Of course, only one of them will subsequently succeed in
        reacquiring the condition variable's lock object.
<p>
<li><a name="an2620"></a><code >void wait(unique_lock&lt;mutex&gt;&amp; uniqueLock)</code>:<br/>before calling <code >wait</code> the current thread must have acquired the lock
        of <code >uniqueLock</code>. Calling <code >wait</code> releases the lock, and the current
        thread is blocked until it has received a notification from another
        thread, and has reacquired the lock.
<p>
<li><code >void wait(unique_lock&lt;mutex&gt;&amp; uniqueLock, Predicate pred)</code>:<br/>this is a member template, using the template header <code >template
        &lt;typename Predicate&gt;</code>. 
       The template's type is automatically derived from the function's
        argument type and does not have to be specified explicitly.
<p>
Before calling <code >wait</code> the current thread must have acquired the lock
        of <code >uniqueLock</code>. As long as `<code >pred</code>' returns <code >false</code>
        <code >wait(lock)</code> is called.
<p>
<li><a name="an2621"></a><code >cv_status wait_for(unique_lock&lt;mutex&gt; &amp;uniqueLock,
                      std::chrono::duration&lt;Rep, Period&gt; const &amp;relTime)</code>:<br/>this member is defined as a member template, using the template header
        <code >template &lt;typename Rep, typename Period&gt;</code>.  
       The template's types are automatically derived from the types of the
        function's arguments and do not have to be specified explicitly.
       E.g., to wait for at most 5 seconds <code >wait_for</code> can be called like
        this:
       <pre>
cond.wait_for(&amp;unique_lock, std::chrono::seconds(5));
</pre>
<p>
This member returns when being notified or when the time interval
        specified by <code >relTime</code> has passed.
<p>
When returning due to a timeout, <code >std::cv_status::timeout</code> is
        returned, otherwise <code >std::cv_status::no_timeout</code> is
        returned.
<p>
Threads should verify that the required data condition has been met
        after <code >wait_for</code> has returned.
<p>
<li><code >bool wait_for(unique_lock&lt;mutex&gt; &amp;uniqueLock,
                      chrono::duration&lt;Rep, Period&gt; const &amp;relTime, Predicate
                       pred)</code>:<br/>this member is defined as a member template, using the template
        header <code >template &lt;typename Rep, typename Period, typename
        Predicate&gt;</code>. 
       The template's types are automatically derived from the types of the
        function's arguments and do not have to be specified explicitly.
<p>
As long as <code >pred</code> returns false, the previous <code >wait_for</code> member is
        called. If the previous member returns <code >cv_status::timeout</code>, then
        <code >pred</code> is returned, otherwise <code >true</code>.
<p>
<li><a name="an2622"></a><code >cv_status wait_until(unique_lock&lt;mutex&gt;&amp; uniqueLock,
                        chrono::time_point&lt;Clock, Duration&gt; const &amp;absTime)</code>:<br/>this member is defined as a member template, using the template
        header <code >template &lt;typename Clock, typename Duration&gt;</code>. 
       The template's types are automatically derived from the types of the
        function's arguments and do not have to be specified explicitly.
       E.g., to wait until 5 minutes after the current time <code >wait_until</code> can
        be called like this:
       <pre>
cond.wait_until(&amp;unique_lock, chrono::system_clock::now() +
                              std::chrono::minutes(5));
</pre>
<p>
This function acts identically to the <code >wait_for(unique_lock&lt;mutex&gt;
        &amp;uniqueLock, chrono::duration&lt;Rep, Period&gt; const &amp;relTime)</code> member
        described earlier, but uses an absolute point in time, rather than a
        relative time specification. 
<p>
This member returns when being notified or when the time interval
        specified by <code >relTime</code> has passed.
       When returning due to a timeout, <code >std::cv_status::timeout</code> is
        returned, otherwise <code >std::cv_status::no_timeout</code> is
        returned.
<p>
<li><code >bool wait_until(unique_lock&lt;mutex&gt; &amp;lock,
                  chrono::time_point&lt;Clock, Duration&gt; const &amp;absTime,
                  Predicate pred)</code>:<br/>this member is defined as a member template, using the template header
        <code >template &lt;typename Clock, typename Duration, typename Predicate&gt;</code>.
       The template's types are automatically derived from the types of the
        function's arguments and do not have to be specified explicitly.
<p>
As long as <code >pred</code> returns false, the previous <code >wait_until</code> member
        is called. If the previous member returns <code >cv_status::timeout</code>, then
        <code >pred</code> is returned, otherwise <code >true</code>.
    </ul> 
    Threads should verify that the required condition is <code >true</code> when
wait-members of condition variables return.
<p>
<a name="CONDVAR2"></a><a name="l506"></a>
<h3 >20.4.2: The class std::condition_variable_any</h3>
    Different from the class <code >condition_variable</code> the class
    <a name="an2623"></a><code >std::condition_variable_any</code> can be used with
any (e.g., user supplied) lock type, and not just with the stl-provided
<code >unique_lock&lt;mutex&gt;</code>.
<p>
Before using the class <code >condition_variable_any</code> the <a name="an2624"></a><code >&lt;condition_variable&gt;</code>
header file must be included.
<p>
The functionality that is offered by <code >condition_variable_any</code> is identical
to the functionality offered by the class <code >condition_variable</code>, albeit that
the lock-type that is used by <code >condition_variable_any</code> is not
predefined. The class <code >condition_variable_any</code> therefore requires the
specification of the lock-type that must be used by its objects.
<p>
In the interface shown below this lock-type is referred to as
<a name="an2625"></a><code >Lock</code>. Most of <code >condition_variable_any's</code> members are defined as
member templates, defining a <code >Lock</code> type as one of its parameters. The
requirements of these lock-types are identical to those of the stl-provided
<code >unique_lock</code>, and user-defined lock-type implementations should provide at
least the interface and semantics that is also provided by <code >unique_lock</code>.
<p>
This section merely presents the interface of the class
<code >condition_variable_any</code>. As its interface offers the same members as
<code >condition_variable</code> (allowing, where applicable, passing any lock-type
instead of just <code >unique_lock</code> to corresponding members), the reader is
referred to the previous section for a description of the semantics of the
class members.
<p>
Like <code >condition_variable</code>, the class <code >condition_variable_any</code> only
offers a default constructor. No copy constructor or overloaded assignment
operator is provided.
<p>
Also, like <code >condition_variable</code>, the class's destructor requires that no
thread is blocked by the current thread. This implies that all other (waiting)
threads must have been notified; those threads may, however, subsequently
block on the lock specified in their <code >wait</code> calls.
<p>
Note that, in addition to <code >Lock</code>, the types <code >Clock, Duration, Period,
Predicate,</code> and <code >Rep</code> are template types, defined just like the identically
named types mentioned in the previous section.
<p>
Assuming that <code >MyMutex</code> is a user defined mutex type, and that <code >MyLock</code> is
a user defined lock-type (cf. section <a href="cplusplus20.html#LOCKS">20.3</a> for details about
lock-types), then a <code >condition_variable_any</code> object can be defined and used
like this:
        <pre>
    MyMutex mut;
    MyLock&lt;MyMutex&gt; ul(mut);
    condition_variable_any cva;

    cva.wait(ul);
</pre>
<p>
These are the class <code >condition_variable_any's</code> members:
    <ul>
    <li><a name="an2626"></a><code >void notify_one() noexcept;</code>
    <li><a name="an2627"></a><code >void notify_all() noexcept;</code>
    <li><a name="an2628"></a><code >void wait(Lock&amp; lock);</code>
    <li><code >void wait(Lock&amp; lock, Predicate pred);</code>
    <li><a name="an2629"></a><code >cv_status wait_until(Lock&amp; lock, const
        chrono::time_point&lt;Clock, Duration&gt;&amp; absTime);</code>
    <li><code >bool wait_until(Lock&amp; lock, const chrono::time_point&lt;Clock, Duration&gt;&amp;
        absTime, Predicate pred);</code> 
    <li><a name="an2630"></a><code >cv_status wait_for(Lock&amp; lock, const chrono::duration&lt;Rep,
        Period&gt;&amp; relTime);</code> 
    <li><code >bool wait_for(Lock&amp; lock, const chrono::duration&lt;Rep, Period&gt;&amp;
        relTime,)</code> <code >Predicate pred</code>; 
    </ul>
<p>
<a name="CONDEX"></a><a name="l507"></a>
<h3 >20.4.3: An example using condition variables</h3>
    Condition variables are used to synchronize threads on the values of data,
rather than on the mere access to data (for which plain mutex-objects can be
used). Using condition variables, a thread simply sleeps until it is notified
by another thread. In a producer-consumer type of program this is usually
accomplished like this:
        <pre>
    consumer loop:
        - wait until there's an item in store,
            then reduce the number of stored items
        - remove the item from the store
        - increment the number of available storage locations
        - do something with the retrieved item

    producer loop:
        - produce the next item
        - wait until there's room to store the item,
            then reduce the number of available storage locations
        - store the item
        - increment the number of stored items
</pre>
<p>
It is important that the two storage administrative tasks (registering the
number of available items and available storage locations) are either
performed by the client or by the producer. For the consumer `waiting' means:
    <ul>
    <li> Get a lock on the variable containing the actual count
    <li> As long as the count is zero: wait, releasing the lock until another
        thread has increased the count, then re-acquire the lock.
    <li> Reduce the count
    <li> Release the lock.
    </ul>
    This scheme is implemented in a class <a name="an2631"></a><code >Semaphore</code>, offering members
<code >wait</code> and <code >notify_all</code>. For a more extensive discussion of semaphores see
<em ><a name="an2632"></a>Tanenbaum, A.S. and <a name="an2633"></a>Austin, T.</em> (2013)
    <a name="an2634"></a>Structured Computer Organization, Pearson Prentice-Hall.
<p>
The data member containing the actual count is called <code >d_available</code>. It is
protected by <code >mutex d_mutex</code>.  In addition a <code >condition_variable
d_condition</code> is defined:
        <pre>
    mutable std::mutex d_mutex;
    std::condition_variable d_condition;
    size_t d_available;
</pre>
<p>
The waiting process is implemented through its member function <code >wait</code>:
        <pre>
     1: void Semaphore::wait()
     2: {
     3:     std::unique_lock&lt;std::mutex&gt; lk(d_mutex);   // get the lock
     4:     while (d_available == 0)
     5:         d_condition.wait(lk);   // internally releases the lock
     6:                                 // and waits, on exit
     7:                                 // acquires the lock again
     8:     --d_available;              // dec. available
     9: }   // the lock is released
</pre>
    In line 5 <code >d_condition.wait</code> releases the lock. It waits until receiving
a notification, and re-acquires the lock just before returning. Consequently,
<code >wait's</code> code always has complete and unique control over <code >d_available</code>.
<p>
What about notifying the a waiting thread? This is handled in lines 4 and
5 of the  member function <code >notify_all</code>:
        <pre>
     1: void Semaphore::notify_all()
     2: {
     3:     std::lock_guard&lt;std::mutex&gt; lk(d_mutex);    // get the lock
     4:     if (d_available++ == 0)
     5:         d_condition.notify_all();   // use notify_one to notify one other
     6:                                     // thread
     7: }   // the lock is released
</pre>
    At line 4 <code >d_available</code> is always incremented; by using a postfix
increment it can simultaneously be tested for being zero. If it was initially
zero then <code >d_available</code> is now one. A thread waiting until <code >d_available</code>
exceeds zero may now continue. A waiting thread is notified by calling
<code >d_condition.notify_one</code>. In situations where multiple threads are waiting
`<a name="an2635"></a><code >notify_all</code>' can also be used.
<p>
Using the facilities of the class <code >Semaphore</code> whose constructor expects
an initial value of its <code >semaphore</code> data member, the classic
consumer-producer paradigm can now be implemented using
multi-threading&nbsp;(A more elaborate example of the producer-consumer
program is found in the <code >yo/threading/examples/events.cc</code> file in the
<strong >C++</strong> Annotations's source archive):
        <pre>
    Semaphore available(10);
    Semaphore filled(0);
    std::queue itemQueue;

    void consumer()
    {
        while (true)
        {
            filled.wait();
                // mutex lock the queue with multiple consumers
            size_t item = itemQueue.front();
            itemQueue.pop();
            available.notify_all();
            process(item);      // not implemented here
        }
    }

    void producer()
    {
        size_t item = 0;
        while (true)
        {
            ++item;
            available.wait();
                // mutex lock the queue with multiple consumers
            itemQueue.push(item);
            filled.notify_all();
        }
    }
    int main()
    {
        thread consume(consumer);
        thread produce(producer);

        consume.join();
        produce.join();
    }
</pre>
<p>
<a name="l508"></a>
<h2 >20.5: Atomic actions: mutexes not required</h2>
Before using the facilities introduced in this section the <a name="an2636"></a><code >&lt;atomic&gt;</code> header
file must be included.
<p>
When data are shared among multiple threads, data corruption is usually
prevented using mutexes. To increment a simple <code >int</code> using this strategy
code as shown below is commonly used:
        <pre>
    {
        lock_guard&lt;mutex&gt; lk{ intVarMutex };
        ++intVar;
    }
</pre>
<p>
The compound statement is used to limit the <code >lock_guard's</code> lifetime, so
that <code >intVar</code> is only locked for a short little while.
<p>
This scheme is not complex, but at the end of the day having to define a
<code >lock_guard</code> for every single use of a simple variable, and having to define
a matching mutex for each simple variable is a bit annoying and cumbersome.
<p>
<strong >C++</strong> offers a way out through the use of <a name="an2637"></a><em >atomic data types</em>.
Atomic data types are available for all basic types, and also for (trivial)
user defined types. Trivial types are (see also section <a href="cplusplus23.html#TYPETRAITS">23.6.2</a>) all
scalar types, arrays of elements of a trivial type, and classes whose
constructors, copy constructors, and destructors all have default
implementations, and their non-static data members are themselves of trivial
types.
<p>
The class template <a name="an2638"></a><code >std::atomic&lt;Type&gt;</code> is available for all
built-in types, including pointer types. E.g., <code >std::atomic&lt;bool&gt;</code> defines
an atomic <code >bool</code> type. For many types alternative somewhat shorter
type names are available. E.g, instead of <code >std::atomic&lt;unsigned short&gt;</code> the
type <code >std::atomic_ushort</code> can be used. Refer to the <code >atomic</code> header file
for a complete list of alternate names.
<p>
If <code >Trivial</code> is a user-defined trivial type then
        <a name="an2639"></a><code >std::atomic&lt;Trivial&gt;</code>
defines an atomic variant of <code >Trivial</code>: such a type does not require 
a separate <code >mutex</code> to synchronize access by multiple threads.
<p>
Objects of the class template <code >std::atomic&lt;Type&gt;</code> cannot directly be copied
or assigned to each other. However, they can be initialized by values of type
<code >Type</code>, and values of type <code >Type</code> can also directly be assigned to
<code >std::atomic&lt;Type&gt;</code> objects. Moreover, since <code >atomic&lt;Type&gt;</code> types offer
conversion operators returning their <code >Type</code> values, an <code >atomic&lt;Type&gt;</code>
objects can also be assigned to or initialized by another <code >atomic&lt;Type&gt;</code>
object using a <code >static_cast</code>:
        <pre>
    atomic&lt;int&gt; a1 = 5;
    atomic&lt;int&gt; a2{ static_cast&lt;int&gt;(a1) };
</pre>
<p>
The class <code >std::atomic&lt;Type&gt;</code> provides several public members, shown
below. Non-member (free) functions operating on <code >atomic&lt;Type&gt;</code> objects are
also available.
<p>
The <code >std::memory_order</code> enumeration defines the following symbolic
constants, which are used to specify ordering constraints of atomic operations:
    <ul>
    <li><code >memory_order_acq_rel:</code> the operation must be a read-modify-write
        operation, combining <code >memory_order_acquire</code> and
        <code >memory_order_release</code>; 
    <li><code >memory_order_acquire:</code> the operation is an acquire operation. It
        synchronizes with a release operation that wrote the same memory
        location; 
    <li><code >memory_order_consume:</code> the operation is a consume operation on the
        involved memory location;
    <li><code >memory_order_relaxed:</code> no ordering constraints are provided by the
        operation;
    <li><code >memory_order_release:</code> the operation is a release operation. It
        synchronizes with acquire operations on the same location;
    <li><code >memory_order_sec_cst:</code> the default memory order specification for all
        operations. Memory storing operations use <code >memory_order_release</code>,
        memory load operations use <code >memory_order_acquire</code>, and
        read-modify-write operations use <code >memory_order_acq_rel</code>.
    </ul>
<p>
The memory order cannot be specified for the overloaded operators provided by
<code >atomic&lt;Type&gt;</code>. Otherwise, most <code >atomic</code> member functions may also be
given a final <code >memory_order</code> argument. Where this is not available it is
explictly mentioned at the function's description.
<p>
Here are the standard available <code >std::atomic&lt;Type&gt;</code> member functions:
    <ul>
    <li><a name="an2640"></a><code >bool compare_exchange_strong(Type
        &amp;currentValue, Type newValue) noexcept</code>:<br/>The value in the atomic object is compared to <code >newValue</code> using
        byte-wise comparisons. If equal (and <code >true</code> is returned) then
        <code >newValue</code> is stored in the atomic object; if unequal (and <code >false</code>
        is returned) the object's current value is stored in
        <code >currentValue</code>;
<p>
<li><a name="an2641"></a><code >bool compare_exchange_weak(Type &amp;oldValue,
        Type newValue) noexcept</code>:<br/>The value in the atomic object is compared to <code >newValue</code> using
        byte-wise comparisons. If equal (and <code >true</code> is returned),
        then <code >newValue</code> is stored in the atomic object; if unequal, or
        <code >newValue</code> cannot be atomically assigned to the current object
        <code >false</code> is returned and the object's current value is stored in
        <code >currentValue</code>;
<p>
<li><a name="an2642"></a><code >Type exchange(Type newValue) noexcept</code>:<br/>The object's current value is returned, and <code >newValue</code> is assigned
        to the current object;
<p>
<li><a name="an2643"></a><code >bool is_lock_free() const noexept</code>:<br/>If the operations on the current object can be performed lock-free
        <code >true</code> is returned, otherwise <code >false</code>.
        This member has no <code >memory_order</code> parameter;
<p>
<li><a name="an2644"></a><code >Type load() const noexcept</code>:<br/>The object's value is returned;
<p>
<li><code >operator Type() const noexcept</code>:<br/>The object's value is returned;
<p>
<li><a name="an2645"></a><code >void store(Type newValue) noexcept</code>:<br/><code >NewValue</code> is assigned to the current object. Note that the standard
        assignment operator can also be used.
    </ul>
<p>
In addition to the above members, integral atomic types `<code >Integral</code>'
(essentially the atomic variants of all built-in integral types) also offer
the following member functions:
    <ul>
    <li><a name="an2646"></a><code >Integral fetch_add(Integral value) noexcept</code>:<br/><code >Value</code> is added to the object's value, and the object's
        value at the time of the call is returned;
<p>
<li><a name="an2647"></a><code >Integral fetch_sub(Integral value) noexcept</code>:<br/><code >Value</code> is subtracted from the object's value, and the object's
        value at the time of the call is returned;
<p>
<li><a name="an2648"></a><code >Integral fetch_and(Integral mask) noexcept</code>:<br/>The <code >bit-and</code> operator is applied to the object's value and
        <code >mask</code>, assigning the resulting value to the current object. The
        object's value at the time of the call is returned;
<p>
<li><a name="an2649"></a><code >Integral fetch_|=(Integral mask) noexcept</code>:<br/>The <code >bit-or</code> operator is applied to the object's value and <code >mask</code>,
        assigning the resulting value to the current object. The object's
        value at the time of the call is returned;
<p>
<li><a name="an2650"></a><code >Integral fetch_^=(Integral mask) noexcept</code>:<br/>The <code >bit-xor</code> operator is applied to the object's value and
        <code >mask</code>, assigning the resulting value to the current object. The
        object's value at the time of the call is returned;
<p>
<li><a name="an2651"></a><code >Integral operator++() noexcept</code>:<br/>The prefix increment operator, returning object's new value;
<p>
<li><a name="an2652"></a><code >Integral operator++(int) noexcept</code>:<br/>The postfix increment operator, returning the object's value before it
        was incremented;
<p>
<li><a name="an2653"></a><code >Integral operator--() noexcept</code><blockquote >The prefix decrement operator, returning object's new value;</blockquote>
<p>
<li><a name="an2654"></a><code >Integral operator--(int) noexcept</code><blockquote >The postfix decrement operator, returning the object's value
            before it was decremented;</blockquote>
<p>
<li><a name="an2655"></a><code >Integral operator+=(Integral value) noexcept</code>:<br/><code >Value</code> is added to the object's current value and the object's
        new value is returned;
<p>
<li><a name="an2656"></a><code >Integral operator-=(Integral value) noexcept</code>:<br/><code >Value</code> is subtracted from the object's current value and the
        object's new value is returned;
<p>
<li><a name="an2657"></a><code >Integral operator&amp;=(Integral mask) noexcept</code>:<br/>The <code >bit-and</code> operator is applied to the object's current value and
        <code >mask</code>, assigning the resulting value to the current object. The
        object's new value is returned;
<p>
<li><a name="an2658"></a><code >Integral operator|=(Integral mask) noexcept</code>:<br/>The <code >bit-or</code> operator is applied to the object's current value and
        <code >mask</code>, assigning the resulting value to the current object. The
        object's new value is returned;
<p>
<li><a name="an2659"></a><code >Integral operator^=(Integral mask) noexcept</code>:<br/>The <code >bit-xor</code> operator is applied to the object's current value and
        <code >mask</code>, assigning the resulting value to the current object. The
        object's new value is returned;
    </ul>
<p>
Some of the free member functions have names ending in <code >_explicit</code>. The
<code >_explicit</code> functions define an additional parameter `<a name="an2660"></a><code >memory_order</code>
<code >order</code>', which is not available for the non-<code >_explicit</code> functions (e.g.,
<code >atomic_load(atomic&lt;Type&gt; *ptr)</code> and <code >atomic_load_explicit(atomic&lt;Type&gt;
*ptr, memory_order order)</code>)
<p>
Here are the free functions that are available for all atomic types:
    <ul>
    <li><a name="an2661"></a><code >bool
        std::atomic_compare_exchange_strong(_explicit)(std::atomic&lt;Type&gt; *ptr,
        Type *oldValue, Type newValue) noexept</code>:<br/>returns <code >ptr-&gt;compare_exchange_strong(*oldValue, newValue)</code>;
<p>
<li><a name="an2662"></a><code >bool
        std::atomic_compare_exchange_weak(_explicit)(std::atomic&lt;Type&gt; *ptr,
        Type *oldValue, Type newValue) noexept</code>:<br/>returns <code >ptr-&gt;compare_exchange_weak(*oldValue, newValue)</code>;
<p>
<li><a name="an2663"></a><code >Type
        std::atomic_exchange(_explicit)(std::atomic&lt;Type&gt; *ptr, Type newValue)
        noexept</code>:<br/>returns <code >ptr-&gt;exchange(newValue)</code>;
<p>
<li><a name="an2664"></a><code >void std::atomic_init(std::atomic&lt;Type&gt; *ptr, Type
        init) noexept</code>:<br/>Stores <code >init</code> <em >non</em>-atomically in <code >*ptr</code>. The object pointed to
        by <code >ptr</code> must have been default constructed, and as yet no member
        functions must have been called for it.
        This function has no <code >memory_order</code> parameter;
<p>
<li><a name="an2665"></a><code >bool std::atomic_is_lock_free(std::atomic&lt;Type&gt;
        const *ptr) noexept</code>:<br/>returns <code >ptr-&gt;is_lock_free()</code>.
        This function has no <code >memory_order</code> parameter;
<p>
<li><a name="an2666"></a><code >Type
        std::atomic_load(_explicit)(std::atomic&lt;Type&gt; *ptr) noexept</code>:<br/>returns <code >ptr-&gt;load()</code>;
<p>
<li><a name="an2667"></a><code >void
        std::atomic_store(_explicit)(std::atomic&lt;Type&gt; *ptr, Type value)
        noexept</code>:<br/>calls <code >ptr-&gt;store(value)</code>.
    </ul>    
<p>
In addition to the abovementioned free functions <code >atomic&lt;Integral&gt;</code> types
also offer the following free member functions:
    <ul>
    <li><a name="an2668"></a><code >Integral
        std::atomic_fetch_add(_explicit)(std::atomic&lt;Integral&gt; *ptr, Integral
        value) noexcept</code>:<br/>returns <code >ptr-&gt;fetch_add(value)</code>;
<p>
<li><a name="an2669"></a><code >Integral
        std::atomic_fetch_sub(_explicit)(std::atomic&lt;Integral&gt; *ptr, Integral
        value) noexcept</code>:<br/>returns <code >ptr-&gt;fetch_sub(value)</code>;
<p>
<li><a name="an2670"></a><code >Integral
        std::atomic_fetch_and(_explicit)(std::atomic&lt;Integral&gt; *ptr, Integral
        mask) noexcept</code>:<br/>returns <code >ptr-&gt;fetch_and(value)</code>;
<p>
<li><a name="an2671"></a><code >Integral
        std::atomic_fetch_or(_explicit)(std::atomic&lt;Integral&gt; *ptr, Integral
        mask) noexcept</code>:<br/>returns <code >ptr-&gt;fetch_or(value)</code>;
<p>
<li><a name="an2672"></a><code >Integral
        std::atomic_fetch_xor(_explicit)(std::atomic&lt;Integral&gt; *ptr, Integral
        mask) noexcept</code>:<br/>returns <code >ptr-&gt;fetch_xor(mask)</code>.
    </ul>
<p>
<a name="l509"></a>
<h2 >20.6: An example: threaded quicksort</h2>
The quicksort sorting algorithm (Hoare, 1962) is a well-known sorting
algorithm. Given an array of <code >n</code> elements, it works like this:
    <ul>
    <li> Pick an element from the array, and partition the array with respect
        to this element (call it the <em >pivot element</em>) (in the example below,
        assume a function <code >partition</code> performing the partition is
        available). This leaves us with two (possibly empty) sub-arrays: one
        to the left of the pivot element, and one to the right of the pivot
        element;
    <li> Recursively perform quicksort on the left-hand sub-array;
    <li> Recursively perform quicksort on the right-hand sub-array.
    </ul>
<p>
To convert this algorithm to a multi-threaded algorithm appears to be be a
simple task: 
        <pre>
    void quicksort(Iterator begin, Iterator end)
    {
        if (end - begin &lt; 2)            // less than 2 elements are left
            return;                     // and we're done

        Iter pivot = partition(begin, end); // determine an iterator pointing
                                            // to the pivot element

        thread lhs(quicksort, begin, pivot);// start threads on the left-hand
                                            // side sub-arrays
        thread rhs(quicksort, pivot + 1, end);  // and on the right-hand side
                                                // sub-arrays
        lhs.join();
        rhs.join();                         // and we're done
    }
</pre>
<p>
Unfortunately, this translation to a multi-threaded approach won't work for 
reasonably large arrays because of a phenomenon called <a name="an2673"></a><em >overpopulation</em>:
more threads are started than the operating system is prepared to give us. In
those cases a <em >Resource temporarily unavailable</em> exception is thrown, and
the program ends.
<p>
Overpopulation can be avoided by using a <em >pool of workers</em>, where each
`worker' is a thread, which in this case is responsible for handling one (sub)
array, but not for the nested calls. The pool of workers is controlled by a
scheduler, receiving the requests to sort sub-arrays, and passing these
requests on to the next available worker. 
<p>
The main data structure of the example program developed in this section is a
queue of <code >std::pairs</code> containing iterators of the array to be sorted
(cf. Figure <a href="cplusplus20.html#sorting">25</a>, the sources of the program are found in the <strong >C++</strong> Annotations's
<code >yo/threading/examples/multisort</code> directory). Two queues are being used: one
queue is a task-queue, receiving the iterators of sub-arrays to be
partitioned. Instead of immediately launching new threads (the <code >lhs</code> and
<code >rhs</code> threads in the above example), the ranges to be sorted are pushed on
the task-queue. The other queue is the work-queue: elements are moved from the
task-queue to the work-queue, where they will be processed by one of the
worker threads.
<p>
<p><a name="sorting"></a><figure >
<img src="threading/sorting.gif" >
<figcaption >Figure 25: Data structure used for multi-threading quicksort</figcaption>
</figure></p>

<p>
The program's <code >main</code> function starts the workforce, reads the data, pushes
the arrays <code >begin</code> and <code >end</code> iterators on the task queue and then starts
the scheduler. Once the scheduler ends the sorted array is displayed:
        <pre>
    int main()
    {
        workForce();            // start the worker threads
        readData();             // read the data into vector&lt;int&gt; g_data
        g_taskQ.push(           // prepare the main task
                    Pair(g_data.begin(), g_data.end())
                ); 
        scheduler();            // sort g_data
        display();              // show the sorted elements
    }
</pre>
<p>
The workforce consists of a bunch of detached threads. Each thread represents
a worker, implemented in the function <code >void worker</code>. Since the number of
worker threads is fixed, overpopulation doesn't occur. Once the array has been
sorted and the program stops these detached threads simply end:
        <pre>
    for (size_t idx = 0; idx != g_sizeofWorkforce; ++idx)
        thread(worker).detach();
</pre>
<p>
The scheduler continues for as long as there are sub-arrays to sort. When this
is the case the task queue's front element is moved to the work queue. This
reduces the work queue's size, and prepares an assignment for the next
available worker. The scheduler now waits until a worker is available. Once 
workers are available one of them is informed of the waiting assignment, and
the scheduler waits for the next task:
        <pre>
    void scheduler()
    {
        while (newTask())
        {
            g_workQ.rawPushFront(g_taskQ);
    
            g_workforce.wait();           // wait for a worker to be available
            g_worker.notify_all();            // activate a worker
        }
    }
</pre>
<p>
The function <code >newTask</code> simply checks whether the task queue is empty. If so,
and none of the workers is currently busy sorting a sub-array then the array
has been sorted, and <code >newTask</code> can return <code >false</code>.  When the task queue is
empty but a worker is still busy, it may be that new sub-array dimensions are
going to be placed on the task queue by an active worker. Whenever a worker is
active the <code >Semaphore g_workforce's</code> size is less than the size of the work
force:
        <pre>
    bool wip()
    {
        return g_workforce.size() != g_sizeofWorkforce;
    }
</pre>
        <pre>
    bool newTask()
    {
        bool done;
    
        unique_lock&lt;mutex&gt; lk(g_taskMutex);
        while ((done = g_taskQ.empty()) &amp;&amp; wip())
            g_taskCondition.wait(lk);
    
        return not done;
    }
</pre>
<p>
Each detached worker thread performs a continuous loop. In the loop it waits
for a notification by the scheduler. Once it receives a notification it
retrieves its assignment from the work queue, and partitions the sub-array
specified in its assignment. Partitioning may result in new tasks. Once this
has been completed the worker has completed its assignment: it increments the
available workforce and notifies the scheduler that it should check whether
all tasks have been performed:
        <pre>
    void worker()
    {
        while (true)
        {
            g_worker.wait();      // wait for action
    
            partition(g_workQ.popFront());
            g_workforce.notify_all();
    
            lock_guard&lt;mutex&gt; lk(g_taskMutex);
            g_taskCondition.notify_one();
        }
    }
</pre>
<p>
Sub-arrays smaller than two elements need no partitioning. All larger
sub-arrays are partitioned relative to their first element. The
<code >std::partition</code> generic algorithm does this well, but if the pivot is
itself an element of the array to partition then the pivot's eventual location
is undetermined: it may be found anywhere in the series of elements which are
at least equal to the pivot. The two required sub-arrays, however, can easily
be constructed:
    <ul>
    <li> First call <code >std::partition</code> relative to an array's first element, 
        partitioning the array's remaining elements, returning <code >mid</code>,
        pointing to the first element of the series of elements that are at
        least as large as the array's first element;
    <li> Then swap the array's first element with element to which <code >mid - 1</code>
        points;
    <li> The two sub-arrays range from, respectively, <code >array.begin()</code> to
        <code >mid - 1</code> (elements all smaller than the pivot), and from <code >mid</code> to
        <code >array.end()</code> (elements all at least as large as the pivot).
    </ul>
    The two iterator pairs defining these two sub-arrays are thereupon added
to the task queue, creating two new tasks to be dealt with by the scheduler:
        <pre>
    void partition(Pair const &amp;range)
    {
        if (range.second - range.first &lt; 2)
            return;
    
        auto rhsBegin = partition(range.first + 1, range.second,
                                bind2nd(less&lt;int&gt;(), *range.first));
        auto lhsEnd = rhsBegin - 1;
    
        swap(*range.first, *lhsEnd);
    
        pushTask(range.first, lhsEnd);
        pushTask(rhsBegin, range.second);
    }
</pre>
<p>
<a name="l510"></a>
<h2 >20.7: Shared States</h2>
Just before a thread ends it may have produced some results. These results may
have to to be communicated to other threads. In multi threaded programs
several classes and functions can be used that produce 
    <a name="an2674"></a><em >shared states</em>, making it easy to communicate results
to other threads. Results could be values, objects or exceptions.
<p>
Objects that contain such shared states are called 
    <a name="an2675"></a><em >asynchronous return objects</em>. However,
due to the nature of multi threading, a thread may request the results of an
asynchronous return object before these result are actually available. In
those cases the requesting thread blocks, waiting for the results to become
available. Asynchronous return objects offer <code >wait</code> and <code >get</code> members
which, respectively, <em >wait</em> until the results have become available, and
<em >produce</em> the asynchronous results once they are available. The phrase that
is used to indicate that the results are available is `the shared state has
been made ready'.
<p>
Shared states are made ready by 
    <a name="an2676"></a><em >asynchronous providers</em>. Asynchronous
providers are simply objects or functions providing results to shared
states. Making a shared state ready means that an asynchronous provider
    <ul>
    <li> marks its shared state as being ready, and
    <li> unblocks any waiting threads (e.g., by allowing blocking members,
        like <code >wait</code>, to return).
    </ul>
<p>
Once a shared state has been made ready it contains a value, object, or
exception which can be retrieved by objects having access to the shared
state. While code is waiting for a shared state to become ready the value or
exception that is going to be stored in the shared state may be computed. When
multiple threads try to access the same shared state they must use
synchronizing mechanisms (like mutexes, cf. section <a href="cplusplus20.html#MUTEX">20.2</a>) to prevent
access-conflicts.
<p>
Shared states use reference counting to keep track of the number of
asynchronous return objects or asynchronous providers that hold references to
them. These return objects and providers may release their references to these
shared states <a name="an2677"></a> (which is called `releasing the
shared state). This happens when a return object or provider holds the last
reference to the shared state, and
    <a name="an2678"></a> the shared state is destroyed.
<p>
On the other hand, an asynchronous provider may also 
    <a name="an2679"></a><em >abandon</em> its shared state. In that case the
provider, in sequence,
    <ul>
    <li> stores an exception object of type 
            <a name="an2680"></a><code >std::future_error</code>, holding the error condition
            <code >std::broken_promise</code> in its shared state;
    <li> makes its shared data ready; and
    <li> releases its shared data.
    </ul>
<p>
Objects of the class <code >std::future</code> (see the next section) are asynchronous
return objects. They can be produced by the <code >std::async</code> (section
<a href="cplusplus20.html#ASYNC">20.10</a>) family of functions, and by objects of the classes
<code >std::packaged_task</code> (section <a href="cplusplus20.html#PACKAGE">20.11</a>), and <code >std::promise</code> (section
<a href="cplusplus20.html#PROMISE">20.12</a>).
<p>
<a name="FUTURE"></a><a name="l511"></a>
<h2 >20.8: Asynchronous return objects: std::future</h2>
Condition variables allow threads to wait until data have obtained certain
values. A thread may also have to wait until a sub-thread has finished when
calling a sub-thread's <code >join</code> member. 
<p>
Waiting may be unwelcome: instead of just waiting our thread might also be
doing something useful. It might as well pick up the results produced by a
sub-thread at some point in the future. 
<p>
In fact, exchanging data among threads always poses some difficulties, as it
requires shared variables, and the use of locks and mutexes to prevent data
corruption. Rather than waiting and using locks it would be nice if some
asynchronous task could be started, allowing the initiating thread (or even
other threads) to pick up the result at some point in the future, when the
results are needed, without having to worry about data locks or waiting times.
For situations like these <strong >C++</strong> provides the class <code >std::future</code>.
<p>
Before using the class <a name="an2681"></a> <code >std::future</code> the <a name="an2682"></a><code >&lt;future&gt;</code> header file
must be included.
<p>
Objects of the class template <a name="an2683"></a><code >std::future</code> harbor the results
produced by asynchronously executed tasks. The class <code >std::future</code> is a
class template. Its template type parameter specifies the type of the result
returned by the asynchronously executed task. This type may be <code >void</code>.
<p>
On the other hand, the asynchronously executed task may throw an exception
(ending the task). In that case the <code >future</code> object catches the exception,
and rethrows it once its return value (i.e., the value returned by the
asynchronously executed task) is requested.
<p>
In this section the members of the class template <code >future</code> are
described. <code >Future</code> objects are commonly initialized through anonymous
<code >future</code> objects returned by the factory function <code >std::async</code> or by the
<code >get_future</code> members of the classes <code >std::promise</code>, and
<code >std::packaged_task</code> (introduced in upcoming sections). Examples of the use
of <code >std::future</code> objects are provided in those sections.
<p>
Some of <code >future</code>'s members return a value of the strongly typed
enumeration <a name="an2684"></a><code >std::future_status</code>. This enumeration defines
three symbolic constants: <code >future_status::ready, future_status::timeout,</code>
and <code >future_status::deferred</code>. 
<p>
Error conditions are returned through <code >std::future_error</code>
exceptions. These error conditions are represented by the values of the
strongly typed enumeration <code >std::future_errc</code> (covered in the next section).
<p>
The class <code >future</code> itself provides the following constructors:
    <ul>
    <li><code >future()</code>:<br/>The default constructor constructs an <code >future</code> object that does not
        refer to shared results. Its <code >valid</code> member returns <code >false</code>.
<p>
<li><code >future(future &amp;&amp;tmp) noexcept</code>:<br/>The move constructor is available. Its <code >valid</code> member returns what
        <code >tmp.valid()</code> would haved returned prior to the constructor
        invocation. After calling the move constructor <code >tmp.valid()</code> returns
        <code >false</code>.
    </ul>
    The class <code >future</code> does not offer a copy constructor or an overloaded
assignment operator. 
<p>
Here are the members of the class <code >std::future</code>:
    <ul>
    <li><code >future &amp;operator=(future &amp;&amp;tmp)</code>:<br/>The move assignment operator grabs the information from the <code >tmp</code>
        object; following this, <code >tmp.valid()</code> returns <code >false</code>.
<p>
<li><code >std::shared_future&lt;ResultType&gt; share() &amp;&amp;</code>:<br/>Returns a <code >std::shared_future&lt;ResultType&gt;</code> (see section
        <a href="cplusplus20.html#SHAREDFUTURE">20.9</a>). After calling this function, the <code >future's
        valid</code> member returns <code >false</code>.
<p>
<li><code >ResultType get()</code>:<br/>First <code >wait</code> (see below) is called. Once <code >wait</code> has returned the
        results produced by the associated asynchronous task
        are returned. With <code >future&lt;Type&gt;</code> specifications the returned value
        is the moved shared value if <code >Type</code> supports move assignment,
        otherwise a copy is returned.  With <code >future&lt;Type &amp;&gt;</code> specifications
        a <code >Type &amp;</code> is returned, with <code >future&lt;void&gt;</code> specifications nothing
        is returned. If the shared value is an exception, it is thrown instead
        of returned. After calling this member the <code >future</code> object's
        <code >valid</code> member returns <code >false</code>.
<p>
<li><code >bool valid() const</code>:<br/>Returns <code >true</code> if the (<code >future</code>) object for which <code >valid</code> is
        called refers to an object returned by an asynchronous task.  If
        <code >valid</code> returns <code >false</code>, the <code >future</code> object exists, but in
        addition to <code >valid</code> only its destructor and move constructor can
        safely be called. When other members are called while <code >valid</code>
        returns <code >false</code> a <a name="an2685"></a><code >std::future_error</code> exception is
        thrown (having the value <a name="an2686"></a><code >future_errc::no_state</code>).
<p>
<li><code >void wait() const</code>:<br/>The thread is blocked until the results produced by the associated
        asynchronous task are available.
<p>
<li><code >std::future_status wait_for(chrono::duration&lt;Rep, Period&gt; const
        &amp;rel_time) const</code>:<br/>This member template derives the template types <code >Rep</code> and <code >Period</code>
        from the actually specified duration (cf. section <a href="cplusplus04.html#DURATION">4.2.2</a>). If
        the results contain a deferred function nothing happens. Otherwise
        <code >wait_for</code> blocks
 
        until the results are available or until the amount of time
        specified by <code >rel_time</code> has expired. Possible return values are:
            <ul>
            <li><code >future_status::deferred</code> if the results contains a
                deferred function;
            <li><code >future_status::ready</code> if the results are avaiable;
            <li><code >future_status::timeout</code> if the function is returning because
                the amount of time specified by <code >rel_time</code> has expired. 
            </ul>
<p>
<li><code >future_status wait_until(chrono::time_point&lt;Clock, Duration&gt; const
                                                        &amp;abs_time) const</code>:<br/>This member template derives the template types <code >Clock</code> and
        <code >Duration</code> from the actually specified <code >abs_time</code> (cf. section
        <a href="cplusplus04.html#TIMEPOINT">4.2.4</a>). If the results contain a deferred function nothing
        happens. Otherwise <code >wait_until</code> blocks until the results are
        available or until the point in time specified by <code >abs_time</code> has
        expired. Possible return values are:
           <ul>
            <li><code >future_status::deferred</code> if the results contain a
                deferred function;
            <li><code >future_status::ready</code> if the results are available;
            <li><code >future_status::timeout</code> if the function is returning because
                the point in time specified by <code >abs_time</code> has expired. 
            </ul>
    </ul>
    The class <code >std::future&lt;ResultType&gt;</code> declares the following friends:
        <pre>
    std::promise&lt;ResultType&gt;
</pre>
<p>
(sf. section <a href="cplusplus20.html#PROMISE">20.12</a>), and
        <pre>
    template&lt;typename Function, typename... Args&gt;
        std::future&lt;typename result_of&lt;Function(Args...)&gt;::type&gt; 
        std::async(std::launch, Function &amp;&amp;fun, Args &amp;&amp;...args);
</pre>
<p>
(cf. section <a href="cplusplus20.html#ASYNC">20.10</a>).
<p>
<a name="l512"></a>
<h3 >20.8.1: The std::future_error exception and the std::future_errc enum</h3>
    Members of the class <code >std::future</code> may return errors by throwing
<code >std::future_error</code> exceptions. These error conditions are represented by
the values of the strongly typed enumeration
    <a name="an2687"></a><code >std::future_errc</code> which defines the following symbolic
constants:
    <ul>
    <li><a name="an2688"></a><code >broken_promise</code>
        <blockquote > 
   <code >Broken_promise</code> is thrown when a <code >future</code> object was received whose
    value was never assigned by a <code >promise</code> or <code >packaged_task</code>. For
    example, an object of the class <code >promise&lt;int&gt;</code> should set the value of
    the <code >future&lt;int&gt;</code> object returned by its <code >get_future</code> member
    (cf. section <a href="cplusplus20.html#PROMISE">20.12</a>), but if it doesn't do so, then a
    <code >broken_promise</code> exception is thrown, as illustrated by the following
    program:
   <pre>
 1: std::future&lt;int&gt; fun()
 2: {
 3:     return std::promise&lt;int&gt;().get_future();
 4: }
 5: 
 6: int main()
 7: try
 8: {
 9:     fun().get();
10: }
11: catch (std::exception const &amp;exc)
12: {
13:     std::cerr &lt;&lt; exc.what() &lt;&lt; '\n';
14: }
</pre>
   At line 3 a <code >promise</code> object is created, but its value is never
    set. Consequently, it `breaks its promise' to produce a value: when
    <code >main</code> tries to retrieve its value (in line 9) a <code >std::futue_error</code>
    exception is thrown containing the <code >future_errc::broken_promise</code>
    value</blockquote>
<p>
<li><a name="an2689"></a><code >future_already_retrieved</code> 
        <blockquote >
   <code >Future_already_retrieved</code> is thrown when multiple attempts are made to
    retrieve the <code >future</code> object from, e.g., a <code >promise</code> or
    <code >packaged_task</code> object that (eventually) should be ready. For example:
   <pre>
 1: int main()
 2: {
 3:     std::promise&lt;int&gt; promise;
 4:     promise.get_future();
 5:     promise.get_future();
 6: }
</pre>
   Note that after defining the <code >std::promise</code> object in line 3 it has
    merely been defined: no value is ever assigned to its <code >future</code>. Even
    though no value is assigned to the <code >future</code> object, it <em >is</em> a valid
    object. I.e., after some time the future <em >should</em> be ready, and the
    future's <code >get</code> member should produce a value. Hence, line 4 succeeds,
    but then, in line 5, the exception is thrown as `the future has already
    been retrieved'.</blockquote>
<p>
<li><a name="an2690"></a><code >promise_already_satisfied</code> 
        <blockquote >
   <code >Promise_already_satisfied</code> is thrown when multiple attempts are made to
    assign a value to a <code >promise</code> object. Assigning a value or
    <code >exception_ptr</code> to the <code >future</code> of a <code >promise</code> object may happen
    only once.  For example:
   <pre>
 1: int main()
 2: {
 3:     std::promise&lt;int&gt; promise;
 4:     promise.set_value(15);
 5:     promise.set_value(155);
 6: }
</pre>
        </blockquote>
<p>
<li><a name="an2691"></a><code >no_state</code> 
        <blockquote >
   <code >No_state</code> is thrown when a member function (other than <code >valid</code>, see
    below) of a <code >future</code> object is called when its <code >valid</code> member returns
    <code >false</code>. This happens, e.g., when calling members of a default
    constructed <code >future</code> object. <code >No_state</code> is not thrown for <code >future</code>
    objects returned by the <code >async</code> factory function or returned by the
    <code >get_future</code> members of <code >promise</code> or <code >packaged_task</code> type
    of objects. Here is an example:
   <pre>
 1: int main()
 2: {
 3:     std::future&lt;int&gt; fut;
 4:     fut.get();
 5: }
</pre>
        </blockquote>
    </ul>
<p>
The class   <a name="an2692"></a><code >std::future_error</code> is derived from the class
<code >std::exception</code>, and offers, in addition to the <code >char const *what()
const</code> member also the member <a name="an2693"></a><code >std::error_code const &amp;code() const</code>,
returning an <a name="an2694"></a><code >std::error_code</code> object associated
with the thrown exception. 
<p>
<a name="SHAREDFUTURE"></a><a name="l513"></a>
<h2 >20.9: Shared asynchronous return objects: std::shared_future</h2>
When a thread activates an asynchronous provider (e.g., a <code >std::async</code>) then
the return value of the asynchronously called function becomes available in
its activating thread through a <code >std::future</code> object. The
<code >future</code> object cannot be used by another thread. If this is required (e.g.,
see this chapter's final section) the <code >future</code> object must be converted to a
    <a name="an2695"></a><code >std::shared_future</code> object. 
<p>
Before using the class <code >std::shared_future</code> the <a name="an2696"></a><code >&lt;future&gt;</code> header file
must be included.
<p>
Once a <code >shared_future</code> object is available, its <code >get</code> member (see below)
can repeatedly be called to retrieve the results of the original <code >future</code>
object. This is illustrated by the next small example:
    <pre>
     1: int main()
     2: {
     3:     std::promise&lt;int&gt; promise;
     4:     promise.set_value(15);
     5: 
     6:     auto fut = promise.get_future();
     7:     auto shared1 = fut.share();
     8: 
     9:     std::cerr &lt;&lt; "Result: " &lt;&lt; shared1.get() &lt;&lt; '\n';
    10:               &lt;&lt; "Result: " &lt;&lt; shared1.get() &lt;&lt; '\n';
    11:               &lt;&lt; "Valid: " &lt;&lt; fut.valid() &lt;&lt; '\n';
    12: 
    13:     auto shared2 = fut.share();
    14: 
    15:     std::cerr &lt;&lt; "Result: " &lt;&lt; shared2.get() &lt;&lt; '\n';
    16:               &lt;&lt; "Result: " &lt;&lt; shared2.get() &lt;&lt; '\n';
    17: }
</pre>
    In lines 9 and 10 the <code >promise's</code> results are retrieved multiple times,
but having obtained the <code >shared_future</code> in line 7, the original <code >future</code>
object no longer has an associated shared state. Therefore, when another
attempt is made (in line 13) to obtain the <code >shared_future</code>, a <em >no
associated state</em> exception is thrown and the program aborts.
<p>
However, multiple copies of <code >shared_future</code> objects may co-exist.  When
multiple copies of <code >shared_future</code> objects exist (e.g. in different
threads), the results of the associated asynchronous task are made ready
(become available) at exactly the same moment in time.
<p>
The relationship between the classes <code >future</code> and <code >shared_future</code>
resembles the relationship between the classes <code >unique_ptr</code> and
<code >shared_ptr</code>: there can only be one instance of a <code >unique_pointer</code>,
pointing to data, whereas there can be many instances of a <code >shared_pointer</code>,
each pointing to the same data. 
<p>
The effect of calling any member of a <code >shared_future</code> object for which
<code >valid() == false</code> other than the destructor, the move-assignment operator,
or <code >valid</code> is undefined.
<p>
The class <code >shared_future</code> supports the following constructors:
    <ul>
    <li><code >shared_future() noexcept</code>
        <blockquote >an empty <code >shared_future</code> object is constructed that does not
            refer to shared results. After using this constructor the object's
            <code >valid</code> member returns <code >false</code>.</blockquote>
<p>
<li><code >shared_future(shared_future const &amp;other)</code>
        <blockquote >a <code >shared_future</code> object is constructed that refers to the
            same results as <code >other</code> (if any). After using this constructor
            the object's <code >valid</code> member returns the same value as
            <code >other.valid()</code>.</blockquote>
<p>
<li><code >shared_future(shared_future&lt;Result&gt; &amp;&amp;tmp) noexcept</code>
        <blockquote > Effects: move constructs a shared_future object that refers to
            the results that were originally referred to by <code >tmp</code> (if
            any). After using this constructor the object's <code >valid</code> member
            returns the same value as <code >tmp.valid()</code> returned prior to the
            constructor invocation, and <code >tmp.valid()</code> returns <code >false</code>.</blockquote>
<p>
<li><code >shared_future(future&lt;Result&gt; &amp;&amp;tmp) noexcept</code>
        <blockquote > Effects: move constructs a shared_future object that refers to
            the results that were originally referred to by <code >tmp</code> (if
            any). After using this constructor the object's <code >valid</code> member
            returns the same value as <code >tmp.valid()</code> returned prior to the
            constructor invocation, and <code >tmp.valid()</code> returns <code >false</code>.</blockquote>
    </ul>
<p>
The class's destructor destroys the <code >shared_future</code> object for which it is
called. If the object for which the destructor is called is the last
<code >shared_future</code> object, and no <code >std::promise</code> or
<code >std::packaged_task</code> is associated with the results associated
with the current object, then the results are also destroyed.
<p>
Here are the members of the class <code >std::shared_future</code>:
    <ul>
    <li><code >shared_future&amp; operator=(shared_future &amp;&amp;tmp)</code>:<br/>The move assignment operator releases the current object's shared
        results, and move assigns <code >tmp's</code> results to the current
        object. After calling the move assignment operator the current
        object's <code >valid</code> member returns the same value as <code >tmp.valid()</code>
        returned prior to the invocation of the move assignment operator, and
        <code >tmp.valid()</code> returns <code >false</code>;
<p>
<li><code >shared_future&amp; operator=(shared_future const &amp;rhs)</code>:<br/>The assignment operator releases the current object's shared results,
        and <code >rhs</code>'s results are shared with the current object. After
        calling the assignment operator the current object's <code >valid</code> member
        returns the same value as <code >tmp.valid()</code>;
<p>
<li><code >Result const &amp;shared_future::get() const</code>:<br/>(Specializations for <code >shared_future&lt;Result &amp;&gt;</code> and
        <code >shared_future&lt;void&gt;</code> are also available). This member waits until
        the shared results are available, and subsequently returns <code >Result
        const &amp;</code>. Note that access to the data stored in <code >Results</code>, accessed
        through <code >get</code> is not synchronized. It is the responsibility of the
        programmer to avoid race conditions when accessing <code >Result's</code>
        data. If <code >Result</code> holds an exception, it is thrown when <code >get</code> is
        called;
<p>
<li><code >bool valid() const</code>:<br/>Returns <code >true</code> if the current object refers to shared
            results;
<p>
<li><code >void wait() const</code>:<br/>Blocks until shared results are available (i.e., the associated
        asynchronous task has produced results);
<p>
<li><code >future_status wait_for(const chrono::duration&lt;Rep, Period&gt;&amp; rel_time)
            const</code>:<br/>(The template types <code >Rep</code> and <code >Period</code> normally are derived by the
        compiler from the actual <code >rel_time</code> specification.) If the shared
        results contain a deferred function (cf. section <a href="cplusplus20.html#ASYNC">20.10</a>) nothing
        happens. Otherwise <code >wait_for</code> blocks until the results of the
        associated asynchronous task has produced results, or until the
        relative time specified by <code >rel_time</code> has expired. The member
        returns 
           <ul> 
           <li><code >future_status::deferred</code> if the shared results contain a
            deferred function; <li><code >future_status::ready</code> if the shared results
            are available;
           <li><code >future_status::timeout</code> if the function is returning because
            the amount of time specified by <code >rel_time</code> has expired;</ul>
<p>
<li><code >future_status wait_until(const chrono::time_point&lt;Clock, Duration&gt;&amp;
            abs_time) const</code>:<br/>(The template types <code >Clock</code> and <code >Duration</code> normally are derived by
        the compiler from the actual <code >abs_time</code> specification.) If the
        shared results contain a deferred function nothing happens. Otherwise
        <code >wait_until</code> blocks until the shared results are available or until
        the point in time specified by <code >abs_time</code> has expired. Possible
        return values are:
           <ul>
            <li><code >future_status::deferred</code> if the shared results contain a
                deferred function;
            <li><code >future_status::ready</code> if the shared results are available;
            <li><code >future_status::timeout</code> if the function is returning because
                the point in time specified by <code >abs_time</code> has expired. 
            </ul>
<p>
</ul>
<p>
<a name="ASYNC"></a><a name="l514"></a>
<h2 >20.10: Starting a new thread: std::async</h2>
In this section the function template <a name="an2697"></a><code >std::async</code> is
covered. <code >Async</code> is used to start asynchronous tasks, returning values (or
<code >void</code>) to the calling thread, which is hard to realize merely using the
<code >std::thread</code> class.
<p>
Before using the function <code >async</code> the <a name="an2698"></a><code >&lt;future&gt;</code> header file must be
included. 
<p>
When starting a thread using the facilities of the class <code >std::thread</code> the
initiating thread at some point commonly calls the thread's <code >join</code>
method. At that point the thread must have finished or execution blocks until
<code >join</code> returns. While this often is a sensible course of action, it may not
always be: maybe the function implementing the thread has a return value, or
it could throw an exception.
<p>
In those cases <code >join</code> cannot be used: if an exception leaves a thread, then
your program ends. Here is an example:
    <pre>
     1: void thrower()
     2: {
     3:     throw std::exception();
     4: }
     5: 
     6: int main()
     7: try
     8: {
     9:    std::thread subThread(thrower);
    10: }
    11: catch (...)
    12: {
    13:     std::cerr &lt;&lt; "Caught exception\n";
    14: }
</pre>
    In line 3 <code >thrower</code> throws an exception, leaving the thread. This
exception is not caught by <code >main</code>'s try-block (as it is defined in another
thread). As a consequence, the program terminates.
<p>
This scenario doesn't occur when <code >std::async</code> is used. <code >Async</code> may start a
new asynchronous task, and the activating thread may retrieve the return value
of the function implementing the asynchronous task or any exception leaving
that function from a <code >std::future</code> object returned by the <code >async</code>
function. Basically, <code >async</code> is called similarly to the way a thread is
started using <code >std::thread</code>: it is passed a function and optionally
arguments which are forwarded to the function.
<p>
Although the function implementing the asynchronous task may be passed as
first argument, <code >async's</code> first argument may also be a value of the strongly
typed enumeration <a name="an2699"></a><a name="an2700"></a><a name="an2701"></a><code >std::launch</code>:
        <pre>
    enum class launch
    {
        async,
        deferred
    };
</pre>
<p>
When passing <code >launch::async</code> the asynchronous task immediately starts;
when passing <code >launch::deferred</code> the asynchronous task is deferred. When 
<code >std::launch</code> is not specified the default value <code >launch::async |
launch::deferred</code> is used, giving the implementation freedom of choice, 
usually resulting in deferring execution of the asynchronous task.
<p>
So, here is the first example again, this time using <code >async</code> to start the
sub-thread:
    <pre>
     1: bool fun()
     2: {
     3:     return std::cerr &lt;&lt; "    hello from fun\n";
     4: }
     5: int exceptionalFun()
     6: {
     7:     throw std::exception();
     8: }
     9: 
    10: int main()
    11: try
    12: {
    13:     auto fut1 = std::async(std::launch::async, fun);
    14:     auto fut2 = std::async(std::launch::async, exceptionalFun);
    15: 
    16:     std::cerr &lt;&lt; "fun returned " &lt;&lt; std::boolalpha &lt;&lt; fut1.get() &lt;&lt; '\n';
    17:     std::cerr &lt;&lt; "exceptionalFun did not return " &lt;&lt; fut2.get() &lt;&lt; '\n';
    18: }
    19: catch (...)
    20: {
    21:     std::cerr &lt;&lt; "caught exception thrown by exceptionalFun\n";
    22: }
</pre>
    Now the threads immediately start, but although the results are
available around line 13, the thrown exception isn't terminating the
program. The first thread's return value is made available in line 16, the
exception thrown by the second thread is simply caught by main's try-block
(line 19).
<p>
The function template <code >async</code> has several overloaded versions:
    <ul>
    <li> The basic form expects a function or functor as its first argument,
returning a <code >std::future</code> holding the function's return value or  exception
thrown by the function:
        <pre>
    template &lt;typename Function, class ...Args&gt;
    std::future&lt;
        typename std::result_of&lt; Function(Args ...) &gt;::type
    &gt; std::async(Function &amp;&amp;fun, Args &amp;&amp;...args);
</pre>
<p>
<li> Alternatively, the first argument may be the address of a member
function. In that case the (required) second argument is an object (or a
pointer to an object) of that member function's class. Any remaining arguments
are passed to the member function (see also the remarks below).
<p>
<li> The first argument may also be a combination (using the <code >bit_or</code>
operator) of the enumeration values of the <code >std::launch</code> enumeration:
        <pre>
    template &lt;class Function, class ...Args&gt;
    std::future&lt;typename std::result_of&lt;Function(Args ...)&gt;::type&gt; 
        std::async(std::launch policy, Function &amp;&amp;fun, Args &amp;&amp;...args);
</pre>
<p>
<li> If the first argument specifies <code >std::launch</code> values, the second
argument may also be the address of a member function.  In that case the
(required) thirs argument is an object (or a pointer to an object) of that
member function's class. Any remaining arguments are passed to the member
function (see also the remarks below).
    </ul>
    When calling <code >async</code> all arguments except for the <code >std::launch</code>
argument must be references, pointers or move-constructible objects:
   <ul>
   <li> When a
    member function is specified, then the object for which the member
    function is called must be a named object, an anonymous object, or a
    pointer to a named object. 
   <li> When a named object is passed to the <code >async</code> function template then
    copy construction is used to construct a copy of the argument which is
    then forwarded to the thread-launcher. 
   <li> When an anonymous object is passed to the <code >async</code> function template
    then move construction is used to forward the anonymous object to the
    thread launcher. 
   </ul>
 Once the thread itself starts another move construction is used to construct
an object for the duration of the thread. When a pointer to an object is
passed, the sub-thread uses the object referred to by the pointer, and neither
copy- nor move-construction is required. However, when using a pointer to an
object the programmer should make sure that the object's lifetime exceeds the
duration of the thread (note that this is not automatically guaranteed, as the
asynchronous task may not actually start before the future's <code >get</code> member is
called).
<p>
Because of the default <code >std::launch::deferred | std::launch::async</code> argument
used by the basic <code >async</code> call it is likely that the function which is
passed to <code >async</code> doesn't immediately start. The <code >launch::deferred</code> policy
allows the implementor to defer its execution until the program explicitly
asks for the function's results. Consider the following program:
        <pre>
     1: void fun()
     2: {
     3:     std::cerr &lt;&lt; "    hello from fun\n";
     4: }
     5: 
     6: std::future&lt;void&gt; asyncCall(char const *label)
     7: {
     8:     std::cerr &lt;&lt; label &lt;&lt; " async call starts\n";
     9:     auto ret = std::async(fun);
    10:     std::cerr &lt;&lt; label &lt;&lt; " async call ends\n";
    11:     return ret;
    12: }
    13: 
    14: int main()
    15: {
    16:     asyncCall("First");
    17:     asyncCall("Second");
    18: }
</pre>
    Although <code >async</code> is called in line 9, the program's output may not show
<code >fun's</code> output line when it is run.  This is a result of the (default) use
of <code >lauch::deferred</code>: the system simply defers <code >fun's</code> execution until
requested, which doesn't happen. But the <code >future</code> object that's returned by
<code >async</code> has a member <code >wait</code>. Once <code >wait</code> returns the shred state must be
available. In other words: <code >fun</code> must have finished. Here is what happens
when after line 9 the line <code >ret.wait()</code> is inserted:
        <pre>
    First async call starts
        hello from fun
    First async call ends
    Second async call starts
        hello from fun
    Second async call ends
</pre>
<p>
Actually, evaluation of <code >fun</code> can be requested at the point where we
need its results, maybe even after calling <code >asyncCall</code>, as shown in the next
example:
        <pre>
     1: int main()
     2: {
     3:     auto ret1 = asyncCall("First");
     4:     auto ret2 = asyncCall("Second");
     5: 
     6:     ret1.get();
     7:     ret2.get();
     8: }
</pre>
    Here the <code >ret1</code> and <code >ret2 std::future</code> objects are created, but their
<code >fun</code> functions aren't evaluated yet. Evaluation occurs at lines 6 and 7,
resulting in the following output:
        <pre>
    First async call starts
    First async call ends
    Second async call starts
    Second async call ends
        hello from fun
        hello from fun
</pre>
<p>
The <code >std::async</code> function template is used to start a thread, making its
results available to the calling thread. On the other hand, we may only be
able to <em >prepare</em> (package) a task (a thread), but may have to leave the
completion of the task to another thread. Scenarios like this are realized
through objects of the class <code >std::packaged_task</code>, which is the topic of the
next section.
<p>
<a name="PACKAGE"></a><a name="l515"></a>
<h2 >20.11: Preparing a task for execution: std::packaged_task</h2>
The class template <a name="an2702"></a><code >std::packaged_task</code> allows a program to
`package' a function or functor and pass the package to a thread for further
processing. The processing thread then calls the packaged function, passing it
its arguments (if any). After completing the function the <code >packaged_task's</code>
future is ready, allowing the program to retrieve the results produced by
the function. Thus, functions and the results of function calls can be
transferred between threads.
<p>
Before using the class template <code >packaged_task</code> the <a name="an2703"></a><code >&lt;future&gt;</code> header file
must be included.
<p>
Before describing the class's interface, let's first look at an example to get
an idea about how a <code >packaged_task</code> can be used. Remember that the essence
of <code >packaged_task</code> is that part of your program prepares (packages) a task
for another thread to complete, and that the program at some point needs the
result of the completed task. 
<p>
To clarify what's happening here, let's first look at a real-life
analogon. Every now and then I make an appointment with my garage to have my
car serviced. The `package' in this case are the details about my car: its
make and type determine the kind of actions my garage performs when servicing
it. My neighbor also has a car, which also needs to be serviced every now and
then. This also results in a `package' for the garage. At the appropriate time
me and my neighbor take our cars to the garage (i.e., the packages are passed
to another thread). The garage services the cars (i.e., calls the functions
stored in the <code >packaged_tasks</code> [note that the tasks differ, depending on the
types of the cars]), and performs some actions that are associated with it
(e.g., registering that my or my neighbor's car has been serviced, or order
replacement parts). In the meantime my neighbor and I perform our own
businesses (the program continues while a separate thread runs as well). But
by the end of the day we'd like to use our cars again (i.e., get the results
associated with the <code >packaged_task</code>). A common result in this example is the
garage's bill, which we have to pay (the program obtains the
<code >packaged_task's</code> results).
<p>
Here is a little <strong >C++</strong> program illustrating the use of a <code >packaged_task</code>
(assuming the required headers and <code >using namespace std</code> have been
specified):
    <pre>
     1: mutex carDetailsMutex;
     2: condition_variable condition;
     3: string carDetails;
     4: packaged_task&lt;size_t (std::string const &amp;)&gt; serviceTask;
     5: 
     6: size_t volkswagen(string const &amp;type)
     7: {
     8:     cout &lt;&lt; "performing maintenance by the book for a " &lt;&lt; type &lt;&lt; '\n';
     9:     return type.size() * 75;            // the size of the bill
    10: }
    11: 
    12: size_t peugeot(string const &amp;type)
    13: {
    14:     cout &lt;&lt; "performing quick and dirty maintenance for a " &lt;&lt; type &lt;&lt; '\n';
    15:     return type.size() * 50;             // the size of the bill
    16: }
    17: 
    18: void garage()
    19: {
    20:     while (true)
    21:     {
    22:         unique_lock&lt;mutex&gt; lk(carDetailsMutex);
    23:         while (carDetails.empty())
    24:             condition.wait(lk);
    25: 
    26:         cout &lt;&lt; "servicing a " &lt;&lt; carDetails &lt;&lt; '\n';
    27:         serviceTask(carDetails);
    28:         carDetails.clear();
    29:     }
    30: }
    31: 
    32: int main()
    33: {
    34:     thread(garage).detach();
    35: 
    36:     while (true)
    37:     {
    38:         string car;
    39:         if (not getline(cin, car) || car.empty())
    40:             break;
    41:         {
    42:             lock_guard&lt;mutex&gt; lk(carDetailsMutex);
    43:             carDetails = car;
    44:         }
    45:         serviceTask =  packaged_task&lt;size_t (string const &amp;)&gt;(
    46:                     car[0] == 'v' ? volkswagen : peugeot
    47:                 );
    48:         auto bill = serviceTask.get_future();
    49:         condition.notify_one();
    50:         cout &lt;&lt; "Bill for servicing a " &lt;&lt; car &lt;&lt;
    51:                                 ": EUR " &lt;&lt; bill.get() &lt;&lt; '\n';
    52:     }
    53: }
</pre>
    <ul>
    <li> Lines 1-3 define the variables used for synchronization;
    <li> Line 4 defines a <code >packaged_task: serviceTask</code> is initialized with a
        function (or functor) expecting a <code >string</code>, returning a <code >size_t</code>;
    <li> Lines 6-10 and 12-16 define such functions: <code >volkswagen</code> and
        <code >peugeot</code> represent the tasks to perform when cars of the provided
        types come in for service; presumably they return the bill.
    <li> Lines 18-30 define the function <code >void garage</code>, defining the actions
        performed by the garage when cars come in for service. These actions
        are performed by a separate detached thread, starting in line 34. In a
        continuous loop it waits until it obtains a lock on the
        <code >carDetailsMutex</code> and <code >carDetails</code> is no longer empty. Then, at
        line 27, it passes <code >carDetails</code> to the <code >packaged_task
        `serviceTask'</code>. By itself this is not identical to calling the
        <code >packaged_task's</code> function, but eventually its function will be
        called. At this point the <code >packaged_task</code> receives its function's
        arguments, which it eventually will forward to its configured
        function. Finally, at line 28 it clears <code >carDetails</code>, thus preparing
        itself for the next request.
    <li> Lines 32-53 define <code >main</code>:
        <ul>
        <li> First, at line 34 the anonymous detached thread running
            <code >garage</code> is started.
        </ul>
        Then the program's main loop starts (lines 36-52):
        <ul>
        <li> The main thread reads commands from the standard input until an
            empty or no line is received (lines 38-40).
        <li> By convention the line's first letter starts the car's brand
            (<code >volkswagen</code> or <code >peugeot</code>), and the <code >packaged_task</code>, provided with
            the right servicing function, is constructed
            next (line 45).
        <li> Then, at line 48 the results, stored in a <code >future</code>, are
            retrieved. Although at this point the <code >future</code> might not be
            ready, the <code >future</code> object itself <em >is</em>, and it is simply
            returned as the bill.
        <li> Now we're ready to inform the garage that it can service a car:
            the garage is notified in line 49.
        </ul>
       Anything may happen next: the program may perform any actions,
        but eventually it requests the results produced by the garage.
       <ul>
        <li> The main thread obtains the results by calling <code >bill.get()</code>
            in line 51. If, by this time, the car is still being serviced, the
            bill isn't ready yet, and <code >bill.get()</code> blocks until it is, and
            the bill for servicing a car is shown.
        </ul>
    </ul>
    Now that we've seen an example of a program using a <code >packaged_task</code>,
let's have a look at its interface. Note that the class <code >packaged_task</code> is a
class template: its template type parameter specifies the prototype of a
function or function object implementing the task performed by the
<code >packaged_task</code> object.
<p>
Constructors and destructor:
    <ul>
    <li><code >packaged_task() noexcept</code>:<br/>The default constructor constructs a <code >packaged_task</code> object which is
        not associated with a function or shared state;
<p>
<li><code >explicit packaged_task(ReturnType(Args...) &amp;&amp;function)</code>:<br/>A <code >packaged_task</code> is constructed for a function or functor
        expecting arguments of types <code >Args...</code>, and returning a value of
        type <code >ReturnType</code>. The <code >packaged_task</code> class template specifies
        <code >ReturnType (Args...)</code> as its template type parameter. The
        constructed object contains a shared state, and a (move constructed)
        copy of <code >function</code>.
<p>
Optionally an <code >Allocator</code> may be specified as second template type
        parameter, in which case the first two arguments are
        <a name="an2704"></a><code >std::allocator_arg_t, Allocator const
        &amp;alloc</code>. The type <code >std::allocator_arg_t</code> is a type introduced to
        disambiguate constructor selections, and can simply be specified as
        <code >std::allocator_arg_t()</code>.
<p>
This constructor may throw a <code >std::bad_alloc</code> exception or
        exceptions thrown by <code >function's</code> copy or move constructors
<p>
<li><code >packaged_task(packaged_task &amp;&amp;tmp) noexcept</code>:<br/>The move constructor moves  any existing shared state from <code >tmp</code> to
        the newly constructed object, removing the shared state from <code >tmp</code>.
<p>
<li><code >~packaged_task()</code>:<br/>The object's shared state (if any) is abandoned
    </ul>
<p>
Member functions:
    <ul>
    <li><a name="an2705"></a><code >future&lt;ReturnType&gt; get_future()</code>:<br/>A <code >std::future</code> object is returned holding the results of the
        separately executed thread. When <code >get_future</code> is incorrectly called
        a <code >future_error</code> exception is thrown, containing one of the
        following values:
       <ul>
       <li><code >future_already_retrieved</code> if <code >get_future</code> was already called on a
            <code >packaged_task</code> object containing the same shared state as the
            current object;
        <li><code >no_state</code> if the current object has no shared state.
       </ul>
       Note: Any <code >futures</code> that share the object's shared state may access
        the result returned by the object's task.
<p>
<li><code >void make_ready_at_thread_exit(Args... args)</code>:<br/>Calls <code >void operator()(Args... args)</code> (see below) when the current
        thread exits, once all objects of thread storage duration associated
        with the current thread have been destroyed.
<p>
<li><code >packaged_task &amp;operator=(packaged_task &amp;&amp;tmp)</code>:<br/>The move assignment operator first releases the current object's
        shared state (if available), after which the current object and
        <code >tmp</code> are swapped;
<p>
<li><code >void operator()(Args... args)</code>:<br/>The <code >args</code> arguments are forwarded to the current object's
        stored task. When the stored task returns its return value is stored
        in the current object's shared state. Otherwise any exception thrown
        by the task is stored in the object's shared state. Following this the
        object's shared state is made ready, and any threads blocked in a
        function waiting for the object's shared state to become ready are
        unblocked. A <code >future_error</code> exception is thrown upon error,
        containing 
       <ul>
       <li><code >promise_already_satisfied</code> if the shared state has already been
            made ready;
        <li><code >no_state</code> if the current object does not have any shared state.
       </ul>
       Calling this member synchronizes with calling any member function of a
        <code >(shared_)future</code> object that provides access to the
        <code >packaged_task's</code> results.
<p>
<li><code >void reset()</code>:<br/>Abandons any available shared state, initializing the current object
        to <code >packaged_task(std::move(funct))</code>, where <code >funct</code> is the
        object's stored task. This member may throw the following exceptions:
       <ul>
       <li><code >bad_alloc</code> if memory for the new shared state could not be
            allocated;
        <li> any exception thrown by the move constructor of the task stored in
                the shared state;   
        <li><code >future_error</code> with a <code >no_state</code> error condition if the current
            object contains no shared state.
       </ul>
<p>
<li><code >void swap(packaged_task &amp;other) noexcept</code>:<br/>The shared states and stored tasks of the current object  and other
        are swapped. 
<p>
<li><code >bool valid() const noexcept</code>:<br/>Returns <code >true</code> if the current object contains a shared state,
        otherwise <code >false</code> is returned;
    </ul>
<p>
The following non-member (free) function operating on <code >packaged_task</code>
objects is available:
    <ul>
    <li> <code >void swap+(packaged_task&lt;ReturnType(Args...)&gt; &amp;lhs,</code>
                                                            
            <code >packaged_task&lt;ReturnType(Args...)&gt; &amp;rhs+) noexcept</code>
       <blockquote >Calls <code >lhs.swap(rhs)</code></blockquote>
    </ul>
<p>
<a name="PROMISE"></a><a name="l516"></a>
<h2 >20.12: The class `std::promise'</h2>
In addition to <code >std::packaged_task</code> and <code >std::async</code> the class template
    <a name="an2706"></a><code >std::promise</code> can be used to obtain the results from a
separate thread.
<p>
Before using the class template <code >promise</code> the <a name="an2707"></a><code >&lt;future&gt;</code> header file
must be included.
<p>
A <code >promise</code> is useful to obtain the results from another thread without
further synchronization requirements. Consider the following program:
        <pre>
    void compute(int *ret)
    {
        *ret = 9;
    }
    
    int main()
    {
        int ret = 0;
        std::thread(compute, &amp;ret).detach();
        cout &lt;&lt; ret &lt;&lt; '\n';
    }
</pre>
Chances are that this program shows the value 0: the <code >cout</code> statement is
already executed before the detached thread has had a chance to complete its
work. In this example that problem can easily be solved by using a
non-detached thread, and using the thread's <code >join</code> member, but when multiple
threads are used that requires named threads and as many <code >join</code>
calls. Instead, using a <code >promise</code> might be preferred:
        <pre>
     1: void compute(promise&lt;int&gt; &amp;ref)
     2: {
     3:     ref.set_value(9);
     4: }
     5: 
     6: int main()
     7: {
     8:     std::promise&lt;int&gt; p;
     9:     std::thread(compute, ref(p)).detach();
    10: 
    11:     cout &lt;&lt; p.get_future().get() &lt;&lt; '\n';
    12: }
</pre>
    In this example again a detached thread is used, but its results are kept
for future reference in a <code >promise</code> object, instead of directly being
assigned to a final destination variable. The <code >promise</code> object contains a
<code >future</code> object holding the computed value. The <code >future's get</code> member
blocks until the future has been made ready, at which point the result becomes
available. By then the detached thread may or may not yet have been
completed. If it already completed its work then <code >get</code> immediately returns,
otherwise there will be a slight delay.
<p>
Promises can be useful when implementing a multi threaded version of some
algorithm without having to use additional synchronization statements. As an
example consider matrix multiplications.  Each element of the resulting
product matrix is computed as the inner product of two vectors: the inner
product of a row of the left-hand matrix operand and a column of the
right-hand matrix operand becomes element <code >[row][column]</code> of the resulting
matrix. Since each element of the resulting matrix can independently be
computed from the other elements, a multi threaded implementation is well
possible. In the following example the function <code >innerProduct</code> (lines 4..11)
leaves its result in a <code >promise</code> object:
        <pre>
     1: int m1[2][2] = {{1, 2}, {3, 4}};
     2: int m2[2][2] = {{3, 4}, {5, 6}};
     3: 
     4: void innerProduct(promise&lt;int&gt; &amp;ref, int row, int col)
     5: {
     6:     int sum = 0;
     7:     for (int idx = 0; idx != 2; ++idx)
     8:         sum += m1[row][idx] * m2[idx][col];
     9: 
    10:     ref.set_value(sum);
    11: }
    12: 
    13: int main()
    14: {
    15:     promise&lt;int&gt; result[2][2];
    16: 
    17:     for (int row = 0; row != 2; ++row)
    18:     {
    19:         for (int col = 0; col != 2; ++col)
    20:             thread(innerProduct, ref(result[row][col]), row, col).detach();
    21:     }
    22: 
    23:     for (int row = 0; row != 2; ++row)
    24:     {
    25:         for (int col = 0; col != 2; ++col)
    26:             cout &lt;&lt; setw(3) &lt;&lt; result[row][col].get_future().get();
    27:         cout &lt;&lt; '\n';
    28:     }
    29: }
</pre>
    Each inner product is computed by a separate (anonymous and detached)
thread (lines 17..21), which starts as soon as the run-time system allows it
to start. By the time the threads have finished the resulting inner products
can be retrieved from the promises' futures. Since futures' <code >get</code> members
block until their results are actually available, the resulting matrix can
simply be displayed by calling those members in sequence (lines 23..28).
<p>
So, a <code >promise</code> allows us to use a thread to compute a value (or
exception, see below), which value may then be collected by another thread at
some future point in time. The promise remains available, and as a consequence
further synchronization of the threads and the program starting the threads is
not necessary. When the promise object contains an exception, rather than a
value, its future's <code >get</code> member rethrows the stored exception.
<p>
Here is the class <code >promise's</code> interface. Note that the class <code >promise</code> is
a class template: its template type parameter <code >ReturnType</code> specifies the
template type parameter of the <code >std::future</code> that can be retrieved from it.
<p>
Constructors and destructor:
    <ul>
    <li><code >promise()</code>:<br/>The default constructor constructs a <code >promise</code> object containing a
        shared state. The shared state may be returned by the member
        <code >get_future</code> (see below), but that future has not yet been made
        ready;
<p>
<li><code >promise(promise &amp;&amp;tmp) noexcept</code>:<br/>The move constructor constructs a <code >promise</code> object, transferring
        the ownership of <code >tmp's</code> shared state to the newly constructed
        object. After the object has been constructed, <code >tmp</code> no longer
        contains a shared state;
<p>
<li><code >~promise()</code>:<br/>The object's shared state (if any) is abandoned;
    </ul>
<p>
Member functions:
    <ul>
    <li><code >std::future&lt;ReturnType&gt; get_future()</code>:<br/>A <code >std::future</code> object sharing the current object's shared state is
        returned. A <code >future_error</code> exception is thrown upon error,
        containing 
       <ul>
       <li><code >future_already_retrieved</code> if <code >get_future</code> was already called on a
            <code >packaged_task</code> object containing the same shared state as the
            current object;
        <li><code >no_state</code> if the current object has no shared state.
       </ul>
       Note: Any <code >futures</code> that share the object's shared state may
        access the result returned by the object's task;
<p>
<li><code >promise &amp;operator=(promise &amp;&amp;rhs) noexcept</code>:<br/>The move assignment operator first releases the current object's
        shared state (if available), after which the current object and
        <code >tmp</code> are swapped;
<p>
<li><code >void promise&lt;void&gt;::set_value()</code>:<br/>See below, at the last <code >set_value</code> member's description;
<p>
<li><code >void set_value(ReturnType &amp;&amp;value)</code>:<br/>See below, at the last <code >set_value</code> member's description;
<p>
<li><code >void set_value(ReturnType const &amp;value)</code>:<br/>See the next member function's description;
<p>
<li><code >void set_value(ReturnType &amp;value)</code>:<br/>The argument (<code >value</code>) is atomically stored in the shared state,
        which is then also made ready. A <code >future_error</code> exception is thrown
        upon error, containing
       <ul>
       <li><code >promise_already_satisfied</code> if the shared state has already been
            made ready;
        <li><code >no_state</code> if the current object does not have any shared state.
       </ul>
       Alternatively, any exception thrown by <code >value</code>'s move or copy
        constructor may be thrown;
     
<p>
<li><code >void set_exception(std::exception_ptr obj)</code>:<br/><code >Exception_ptr obj</code> (cf. section <a href="cplusplus20.html#EXCPTR">20.12.1</a>) is atomically stored
        in the shared state, making that state ready. A <code >future_error</code>
        exception is thrown upon error, containing
       <ul>
       <li><code >promise_already_satisfied</code> if the shared state has already been
            made ready;
        <li><code >no_state</code> if the current object does not have any shared state;
       </ul>
<p>
<li><code >void set_exception_at_thread_exit(exception_ptr ptr)</code>:<br/>The exception pointer <code >ptr</code> is stored in the shared state without
        immediately making that state ready. The state becomes ready when the
        current thread exits, once all objects of thread storage duration
        which are associated with the ending thread have been destroyed.  A
        <code >future_error</code> exception is thrown upon error, containing
       <ul>
       <li><code >promise_already_satisfied</code> if the shared state has already been
            made ready;
        <li><code >no_state</code> if the current object does not have any shared state;
       </ul>
<p>
<li><code >void set_value_at_thread_exit()</code>:<br/>See below, at the last <code >set_value_at_thread_exit</code> member's
        description;
<p>
<li><code >void set_value_at_thread_exit(ReturnType &amp;&amp;value)</code>:<br/>See below, at the last <code >set_value_at_thread_exit</code> member's
        description;
<p>
<li><code >void set_value_at_thread_exit(ReturnType const &amp;value)</code>:<br/>See the next <code >set_value_at_thread_exit</code> member's
        description;
<p>
<li><code >void set_value_at_thread_exit(ReturnType &amp;value)</code>:<br/>Stores <code >value</code> in the shared state without immediately making that
        state ready.  The state becomes ready when the current thread exits,
        once all objects of thread storage duration which are associated with
        the ending thread have been destroyed.  A <code >future_error</code> exception
        is thrown upon error, containing
       <ul>
       <li><code >promise_already_satisfied</code> if the shared state has already been
            made ready;
        <li><code >no_state</code> if the current object does not have any shared state;
       </ul>
<p>
<li><code >void swap(promise&amp; other) noexcept</code>:<br/>The shared states (if any) of the current object and <code >other</code> are
        exchanged.
    </ul>
<p>
The following non-member (free) function operating on <code >promise</code> objects is
available:
    <ul>
    <li><code >void swap(promise&lt;ReturnType&gt; &amp;lhs, promise&lt;ReturnType&gt; &amp;rhs)
        noexcept</code>:<br/>Calls <code >lhs.swap(rhs)</code>
    </ul>
<p>
<a name="EXCPTR"></a><a name="l517"></a>
<h3 >20.12.1: Exception propagation: std::exception_ptr</h3>
    <code >Std::promise's</code> member <code >set_exception</code> does not expect a
<code >std::exception</code> argument, but an object of the class
<a name="an2708"></a><code >std::exception_ptr</code>. In this section we take a closer look
at the class <code >exception_ptr</code>.
<p>
Before using the class <code >exception_ptr</code> the <a name="an2709"></a><code >&lt;future&gt;</code> header file
must be included.
<p>
The class <code >exception_ptr's</code> default constructor initializes it to a
null-pointer. In the following code snippet the variable <code >isNull</code> is set to
true:
        <pre>
    std::exception_ptr obj;
    bool isNull =  obj == nullptr &amp;&amp; obj == 0;
</pre>
<p>
The class <code >exception_ptr</code> provides copy and move constructors as well as
copy and move assignment operators.
<p>
Two <code >exception_ptr</code> objects can be compared for equality. They are equal
if they refer to the same exception. Move assignment transfers the exception
referred to by the right-hand side operand to the left-hand side operand, and
turns the right-hand side operand into a null pointer.
<p>
There is no published method directly retrieving the exception to which an
<code >exception_ptr</code> object refers. However, there are some free functions
constructing or handling <code >exception_ptr</code> objects:
    <ul>
    <li><a name="an2710"></a><code >std::exception_ptr std::current_exception() noexcept</code>:<br/>An <code >exception_ptr</code> object is returned referring to the currently
        handled exception (or a copy of the currently handled exception, or a
        default constructed <code >exception_ptr</code> object if no current exception
        is available). This function can also be called when a default
        exception catcher is used. E.g., assuming that <code >obj</code> refers to an
        available <code >std::promise</code> object, then the following code snippet
        assigns the exception caught by default catch clause to <code >obj</code>:
       <pre>
    ...
    catch (...)
    {
        obj.set_exception(std::current_exception());
    }
</pre>
<p>
The exception referred to by <code >current_exception</code> does not have to
        be an object of the class <code >std::exception</code>. Any type of object or
        value thrown as an exception is retrieved as an <code >exception_ptr</code> by
        <code >current_exception</code>. The exception referred to by an
        <code >exception_ptr</code> object remains valid for at least as long as there
        exists an <code >exception_ptr</code> object that refers to it. Calling
        <code >current_exception</code> twice in a row then the two returned
        <code >exception_ptr</code> objects may or may not refer to the same exception
        object.
<p>
<li><a name="an2711"></a><code >std::exception_ptr make_exception_ptr(Type
        value) noexcept</code>:<br/>This function template constructs an <code >exception_ptr</code> from a value of
        any type which is passed as its argument. <code >Type</code> does not
        necessarily have to be a <code >std::exception</code>. The constructed
        <code >exception_ptr</code> could, e.g., be assigned to a <code >std::promise</code>. When
        the promise's future's <code >get</code> member is subsequently called (possibly
        from within another thread) the exception will be thrown. Here are
        some examples, showing how values of different types can be passed as
        arguments to <code >make_exception_ptr</code>, and showing how the eventually
        constructed <code >exception_ptr</code> is assigned to the <code >obj</code>, which is
        assumed to be of a <code >std::promise</code> type:
       <pre>
    auto ptr = make_exception_ptr(exception());
    ptr = make_exception("hello world"s);
    ptr = make_exception(12);

    obj.set_exception(make_exception_ptr(ptr));
</pre>
<p>
<li><a name="an2712"></a><code >void std::rethrow_exception(exception_ptr obj)</code>:<br/>The exception to which <code >obj</code> refers is thrown. Note: <code >obj</code>
        cannot be a <code >nullptr</code>.
<p>
</ul>
<p>
<a name="l518"></a>
<h2 >20.13: An example: multi-threaded compilations</h2>
In this section another program is developed. This section's  example program
illustrates the use of <code >packaged_tasks</code>. 
<p>
Like the multi-threaded quicksort example a worker pool is used. However, in
this example the workers in fact do not know what their task is. In the
current example the tasks happens to be identical, but different tasks might
as well have been used, without having to update the workers.
<p>
The program uses a <code >class Task</code> containing a command-specification
(<code >d_command</code>), and a task specification (<code >d_task</code>) (cf. Figure <a href="cplusplus20.html#compile">26</a>), the
sources of the program are found in the 
<code >yo/threading/examples/multicompile</code> directory of the <strong >C++</strong> Annotations.
<p>
<p><a name="compile"></a><figure >
<img src="threading/compile.gif" >
<figcaption >Figure 26: Data structure used for the multi-threading compilation</figcaption>
</figure></p>

<p>
Like before <code >main</code> first starts its workforce as detached threads. Following
this, the compilation jobs are performed by yet another detached
thread. Eventually, the results of the compilation jobs are handled by
<code >results</code>:
        <pre>
    int main()
    {
        workforce();                    // start the worker threads
        thread(jobs).detach();          // start working on the jobs
        results();                      // handle the results.
    }
</pre>
<p>
The <code >jobs</code>-thread reads the names of the files to compile from the standard
input stream, and passes them on to <code >dispatch</code> for further handling by the
workers. Lines 7 and 8 are executed at the end, and are a safeguard against
empty input. The safeguard is discussed below, at <code >newResult's</code>
description. 
        <pre>
     1: void jobs()
     2: {
     3:     string line;
     4:     while (getline(cin, line) &amp;&amp; dispatch(line))
     5:         ;
     6: 
     7:     g_ready = true;
     8:     g_resultCond.notify_one();
     9: }
</pre>
<p>
Next the dispatcher. It ignores empty lines. Also, if a compilation has
failed by the time the dispatcher is called, processing stops (lines
6-7). Otherwise, the dispatcher waits for an available worker, prepares a new
task, and notifies a worker to handle it:
        <pre>
     1: bool dispatch(string const &amp;line)
     2: {
     3:     if (line.empty())
     4:         return true;
     5: 
     6:     if (g_done.load())
     7:         return false;
     8: 
     9:     g_workforce.wait();
    10:     newTask(line);
    11:     g_worker.notify_all();
    12:     return true;
    13: }
</pre>
<p>
The function <code >newTask</code> prepares the program for the next task. First a
<code >Task</code> object is created. <code >Task</code> contains the name of the file to compile,
and a <code >packaged_task</code>. It encapsulates all activities that are associated
with a <code >packaged_task</code>. Here is its (in-class) definition:
        <pre>
     1: typedef packaged_task&lt;Result (string const &amp;fname)&gt; PackagedTask;
     2: 
     3: class Task
     4: {
     5:     string d_command;
     6:     PackagedTask d_task;
     7: 
     8:     public:
     9:         Task()  = default;
    10: 
    11:         Task(string const &amp;command, PackagedTask &amp;&amp;tmp)
    12:         :
    13:             d_command(command),
    14:             d_task(move(tmp))
    15:         {}
    16: 
    17:         void operator()()
    18:         {
    19:             d_task(d_command);
    20:         }
    21: 
    22:         shared_future&lt;Result&gt; result()
    23:         {
    24:             return d_task.get_future().share();
    25:         }
    26: };
</pre>
<p>
Note (lines 22-25) that <code >result</code> returns a <code >shared_future</code>. Since the
dispatcher runs in a different thread than the one processing the results, the
<code >futures</code> created by the dispatcher must be shared with the <code >futures</code>
required by the function processing the results. Hence the <code >shared_futures</code>
returned by <code >Task::result</code>. 
<p>
Once a <code >Task</code> object has been constructed its <code >shared_future</code> is pushed on
the result queue. Although the actual results aren't available by this time,
the <code >result</code> function (see below) is notified that something has been pushed
on its queue. Additionally, the <code >Task</code> itself is pushed on the task queue,
where a worker may retrieve it:
        <pre>
    class Task
    {
        string d_command;
        PackagedTask d_task;

        public:
            Task()  = default;

            Task(string const &amp;command, PackagedTask &amp;&amp;tmp);
            void operator()();
            shared_future&lt;Result&gt; result();
    };
</pre>
<p>
<pre>
    void pushResultQ(shared_future&lt;Result&gt; const &amp;sharedResult)
    {
        lock_guard&lt;mutex&gt; lk(g_resultQMutex);
        g_resultQ.push(sharedResult);
        g_ready = true;
        g_resultCond.notify_one();
    }
</pre>
<p>
The workers have a simple task: retrieve the next task from the task queue's
front, then perform that task. Whatever happens inside the tasks themselves is
of no concern: the worker thread eventually ends when the program ends:
        <pre>
    void worker()
    {
        Task task;
    
        while (true)
        {
            g_worker.wait();
    
            g_taskQ.popFront(task);
            task();
    
            g_workforce.notify_all();
        }
    }
</pre>
<p>
This completes the description of how tasks are handled. The task itself
remains to be described. In the current example program source files are being
compiled. The compilation command is passed to the constructor of a
<code >CmdFork</code> object, which starts the compiler as a child process. The result
of the compilation is retrieved via its <code >childExit</code> (returning the
compiler's exit code) and <code >childOutput</code> (returning any textual output
produced by the compiler) members. If compilation fails, the exit value won't
be zero. In this case no further compilation tasks will be initiated (lines 11
and 12; the implementation of the <code >class CmdFork</code> is available from the
<strong >C++</strong> Annotations' <code >yo/threading/examples/cmdfork</code> directory). Here is the
function <code >compile</code>:
        <pre>
     1: Result compile(string const &amp;line)
     2: {
     3:     string command("/usr/bin/g++ -Wall --std=c++11 -c " + line);
     4: 
     5:     CmdFork cmdFork(command);
     6:     cmdFork.fork();
     7: 
     8:     Result ret {cmdFork.childExit() == 0,
     9:                 line + "\n" + cmdFork.childOutput()};
    10: 
    11:     if (not ret.ok)
    12:         g_done = true;
    13: 
    14:     return ret;
    15: }
</pre>
<p>
The <code >results</code> function continues for as long as there are results. Once
results are available they are displayed. Whenever a compilation has failed
the <code >Result's d_ok</code> member is <code >false</code> and <code >results</code> ends:
        <pre>
    void results()
    {
        while (newResult())
        {
            Result const &amp;result = g_resultQ.front().get();
    
            cerr &lt;&lt; result.display;
            if (not result.ok)
                return;
    
            g_resultQ.pop();
        }
    }
</pre>
<p>
The function <code >newResult</code> controls <code >results' while</code>-loop. It returns
<code >true</code> when there are some results available in the result queue. When no
filenames are presented at the standard input stream or when no result has as
yet been pushed on the result queue <code >newResult</code> waits. It also waits when 
there are no results available in the results queue, but at least one worker
thread is busy. Whenever a result is pushed on the result queue, and also once
the input stream has been processed <code >newResult</code> is notified. Following the
notification <code >newResult</code> returns, and <code >results</code> either ends or shows the
results appearing at te result queue's front:
        <pre>
    bool newResult()
    {
        unique_lock&lt;mutex&gt; lk(g_resultQMutex);
    
        while
        (
            (
                g_resultQ.empty()
                &amp;&amp;
                g_workforce.size() != g_sizeofWorkforce
            )
            ||
            not g_ready.load()
        )
            g_resultCond.wait(lk);
    
        return not g_resultQ.empty();
    }
</pre>
<p>
<a name="TRANSMEM"></a><a name="l519"></a>
<h2 >20.14: Transactional Memory</h2>

<p>
Transactional memory is used to simplify shared data access in multithreaded
programs. The benefits of transactional memory is best illustrated by a
small program. Consider a situation where threads need to write information to
a file. A plain example of such a program would be:
        <pre>
    void fun(int value)
    {
        for (size_t rept = 0; rept != 10; ++rept)
        {
            this_thread::sleep_for(chrono::seconds(1));
            cout &lt;&lt; "fun " &lt;&lt; value &lt;&lt; '\n';
        }
    };
    
    int main()
    {
        thread thr{ fun, 1 };
        fun(2);
        thr.join();
    }
</pre>
<p>
When this program is run the <code >fun 1</code> and <code >fun 2</code> messages are
intermixed. To prevent this we traditionally define a <code >mutex</code>, lock it,
write the message, and release the lock:
        <pre>
    void fun(int value)
    {
        static mutex guard;

        for (size_t rept = 0; rept != 10; ++rept)
        {
            this_thread::sleep_for(chrono::seconds(1));
            guard.lock();
            cout &lt;&lt; "fun " &lt;&lt; value &lt;&lt; '\n';
            guard.unlock();
        }
    };
</pre>
<p>
Transactional memory handles the locking for us. Transactional memory is used
when statements are embedded in a <a name="an2713"></a><code >synchronized</code> block. The function
<code >fun</code>, using transactional memory, looks like this:
        <pre>
    void fun(int value)
    {
        for (size_t rept = 0; rept != 10; ++rept)
        {
            this_thread::sleep_for(chrono::seconds(1));
            synchronized
            {
                cout &lt;&lt; "fun " &lt;&lt; value &lt;&lt; '\n';
            }
        }
    };
</pre>
<p>
<a name="an2714"></a>
    To compile source files using transactional memory the <code >g++</code> compiler
option <a name="an2715"></a><code >-fgnu-tm</code> must be specified.
<p>
The code inside a synchronized block is executed as a single, as if the
block was protected by a mutex. Different from using mutexes transactional
memory is implemented in software instead of using hardware-facilities.
<p>
Considering how easy it is to use transactional memory compared to using
the <code >mutex</code>-based locking mechanism using transactional memory appears
too good to be true. And in a sense it is. When encountering a synchronized
block the thread unconditionally executes the block's statements. At the same
time it keeps a detailed log of all its actions. Once the statements have been
completed the thread checks whether another thread didn't start executing the
block just before it. If so, it reverses its actions, using the synchronized
block's log. The implication of this should be clear: there's at least the
overhead of maintaining the log, and <em >if</em> another thread started executing 
the synchronized block before the current thread then there's the additional
overhead of reverting its actions and to try again. 
<p>
The advantages of transactional memory should also be clear: the
programmers no longer is responsible for correctly controlling access to
shared memory; risks of encountering deadlocks have disappeared as has all
adminstrative overhead of defining mutexes, locking and unlocking. Especially
for inherently slow operations like writing to files transactional memory can
greatly simplify parts of your code. Consider a <code >std::stack</code>. Its
top-element can be inspected but its <code >pop</code> member does not return the
topmost element. To retrieve the top element and then maybe remove it
traditionally requires a mutex lock surrounding determining the stack's size,
and if empty, release the lock and wait. If not empty then retrieve its
topmost element, followed by removing it from the stack. Using a transactional
memory we get something as simple as:
            <pre>
    bool retrieve(stack&lt;Item&gt; &amp;itemStack, Item &amp;item)
    {
        synchronized
        {
            if (itemStack.empty())
                return false;
            item = std::move(itemStack.top());
            itemStack.pop();
            return true;
        }
    }
</pre>
<p>
Variants of <code >synchronized</code> are:
    <ul>
    <li><a name="an2716"></a><code >atomic_noexcept</code>: the statements inside its compound statement may not
        throw exceptions. If they do, <code >std::abort</code> is called. If the earlier
        <code >fun</code> function specifies <code >atomic_noexcept</code> instead of
        <code >synchronized</code> the compiler generates and error about the use of the
        insertion operator, from which an exception may be thrown.
    <li><a name="an2717"></a><code >atomic_cancel</code>: not yet supported by <code >g++</code> (version 8.2.0). If an
        exception other than (<code >std::</code>) <code >bad_alloc, bad_array_new_length,
        bad_cast, bad_typeid, bad_exception, exception, tx_exception&lt;Type&gt;</code> is
        thrown <code >std::abort</code> is called. If an acceptable exception is thrown,
        then the statements executed so far are undone.
    <li><a name="an2718"></a><code >atomic_commit</code>: if an exception is thrown from its compound statement
        all thus far executed statements are kept (i.e., not undone).
    </ul>
<p>

<hr>
<ul>
    <li> <a href="cplusplus.html">Table of Contents</a>
    <li> <a href="cplusplus19.html">Previous Chapter</a>
    <li> <a href="cplusplus21.html">Next Chapter</a>
</ul>
<hr>
</body>
</html>
